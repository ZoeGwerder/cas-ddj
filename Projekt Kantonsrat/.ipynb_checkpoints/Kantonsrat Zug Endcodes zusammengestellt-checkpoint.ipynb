{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import requests, zipfile, io #zum abspeichern von PDFs\n",
    "from tqdm import tqdm # Anzeigen des aktuellen Ladestandes\n",
    "import PyPDF2\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import locale #für das deutsche Zeitformat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. URL von allen Hauptseiten holen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alle urls und infos der Hauptseiten holen.\n",
    "url = \"https://kr-geschaefte.zug.ch/gast/geschaefte?commit=Filtern&geschaeft_filter%5Babgeschlossen_bis%5D=&geschaeft_filter%5Babgeschlossen_von%5D=&geschaeft_filter%5Barten_refs%5D%5B%5D=&geschaeft_filter%5Beingereicht_bis%5D=&geschaeft_filter%5Beingereicht_von%5D=&geschaeft_filter%5Bfrist_bis%5D=&geschaeft_filter%5Bhistorische_staende_refs%5D%5B%5D=&geschaeft_filter%5Bkommissionen_refs%5D%5B%5D=&geschaeft_filter%5Bstaende_refs%5D%5B%5D=&geschaeft_filter%5Bstatus_ids%5D%5B%5D=haengig&geschaeft_filter%5Bstatus_ids%5D%5B%5D=abgeschlossen&geschaeft_filter%5Bstatus_ids%5D%5B%5D=&geschaeft_filter%5Btitel%5D=&geschaeft_filter%5Bzustaendig_refs%5D%5B%5D=&page=\"\n",
    "\n",
    "alle_seiten = []\n",
    "for seite in range(1,41):\n",
    "    r=requests.get(url+str(seite))\n",
    "    soup = BeautifulSoup(r.text,\"html.parser\")\n",
    "    \n",
    "    tr_list=soup.find_all(\"tr\")[2:] #erst ab der Position 2 sind die Daten relevant.\n",
    "    \n",
    "    for element in tr_list:\n",
    "        td_list = element.find_all(\"td\")\n",
    "        vorlag_nr=td_list[0].text\n",
    "        href = td_list[0].find(\"a\")[\"href\"]\n",
    "        text = td_list[1].text\n",
    "        stand = td_list[2].text\n",
    "        zustaendig = td_list[3].text\n",
    "        geschaeft_art = td_list[4].text\n",
    "        status = td_list[5].text\n",
    "        \n",
    "        mini_dict = {\"VorlageNR\":vorlag_nr,\"url\":href,\"Geschäft\":text, \"Stand\":stand, \"Zuständigkeit\":zustaendig, \"Art des Geschäfts\": geschaeft_art, \"Status\":status}\n",
    "\n",
    "        alle_seiten.append(mini_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(alle_seiten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a=pd.DataFrame(alle_seiten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Geschäftsnummer zur Zahl machen. \n",
    "df_a[\"VorlageNR\"] = df_a[\"VorlageNR\"].astype(int) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Selektion: Fokus auf Vorstösse\n",
    "So will ich eine allzu grosse pdf-Schwemme verhindern.\n",
    "Die Idee: nur jene Geschäfte auf den PC ziehen, die auch relevant sind für die Auswertung. \n",
    "Also nur Vorstösse. Mich so bis zu den PDF's vorkämpfen, um auch hier nur jene auf meinem Rechner zu haben, \n",
    "die ich wirklich auf meinem Rechner will."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#hier mache ich eine Liste, die nur aus denjenigen URLs besteht, die Vorstösse sind. \n",
    "\n",
    "list_of_vorstoss=[\"Motion\",\"Interpellation\",\"Postulat\",\"Kleine Anfrage\", \"Initiative\"]\n",
    "df_v=df_a[df_a[\"Art des Geschäfts\"].isin (list_of_vorstoss)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v #hier habe ich nun alle Vorstösse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_v=df_v.reset_index()#Ich will überall nun denselben Index. deshalb nur soviel, wie ich Zeilen habe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v.to_csv(\"KRFrames/df_v_Hauptseiten\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Eine Liste aus allen Geschäfts-URLs machen (um später auf diese zuzugreiffen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_liste_ganz=[]\n",
    "url_anfang_original=\"https://kr-geschaefte.zug.ch\"\n",
    "for element in df_v[\"url\"]:\n",
    "    url_liste_ganz.append(url_anfang_original+element)\n",
    "#diese werden zusammengefügt aus dem Anfang der Adresse sowie dem Geschäfts-URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(url_liste_ganz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Die einzelnen Geschäfte aufrufen und Infos rausholen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -> Einschub: ich will speichern und mit diesen Daten dann arbeiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#habe nun alle Seiten der Geschäfte auf meinem Rechner gespeichert. \n",
    "number = 0\n",
    "for page in url_liste_ganz:\n",
    "    page_content = requests.get(page)\n",
    "    page_content = page_content.text\n",
    "    with open(\"Geschaeft\"+str(number)+\".html\", \"w\") as file:\n",
    "        file.write(page_content)\n",
    "        file.close()\n",
    "    number +=1\n",
    "    #Es sind nun exakt so viele Seiten auf meinem Rechner, wie das DataFrame oben Zeilen anzeigt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <-Einschub-Ende. Ich habe es geschafft, das zu speichern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nun muss ich den Code ändern, sodass ich nicht mehr online zugreiffe sondern über meinen Ordner.\n",
    "#hier nun die Liste der Zugriffe.\n",
    "geschaefts_liste=[]#####ACHTUNG ich mache den RANGE kleiner, um weniger GEschäfte zu erhalten.\n",
    "\n",
    "for seite_g in range(0,1220): #Range für alle Geschäfte wäre 1219!\n",
    "    gesch= \"KRhtml/Geschaeft\"+str(seite_g)+\".html\"\n",
    "    geschaefts_liste.append(gesch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(geschaefts_liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geschaefts_liste[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Zugang zu den PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ich musste rausfinden, bei welchen Files ich nicht auf die Nummer 1 zugreiffen kann. \n",
    "*Siehe File: \"Falsche Files rausfinden - code anpassen\"* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hier  habe ich mich entschieden, auf den Zugriff der Namen zu verzichten, und dies einheitlich über die PDFs zu lösen.\n",
    "#Nun seite für Seite abrufen und in einem neuen Minidict unterbringen\n",
    "eingang_list=[]\n",
    "\n",
    "\n",
    "for geschaeft in geschaefts_liste:\n",
    "    file = open(geschaeft, 'r')\n",
    "    text = file.read()\n",
    "    soup_g = BeautifulSoup(text, 'html.parser')\n",
    "    tr_g_list=soup_g.find_all(\"tr\")\n",
    "    td_g_list=tr_g_list[-1].find_all(\"td\")#hier gehe ich zum Dokument.\n",
    "    gesch_nr = tr_g_list[-1].find_all(\"td\")[0].text\n",
    "    einger_am = tr_g_list[1].find_all(\"td\")[0].text   \n",
    "   \n",
    "   \n",
    "     #Da es zum Teil Referenzen hat und dadurch ein anderer Ort abgegriffen werden muss, muss ich varieren.\n",
    "    \n",
    "    if td_g_list[-1].find_all(\"a\")[0].text== \"1\": #Ich brauche immer das Dokument 1. \n",
    "        url_v_pdf = td_g_list[-1].find(\"a\")[\"href\"]\n",
    "    elif td_g_list[-1].find_all(\"a\")[0].text== \"2\": #bei älteren GEschäften sind es Bericht&Anträge\n",
    "        url_v_pdf = td_g_list[-1].find(\"a\")[\"href\"]   \n",
    "    else: \n",
    "        td_g_list[-1].find_all(\"a\")[0].text== \"3\"\n",
    "        url_v_pdf = td_g_list[-1].find(\"a\")[\"href\"]\n",
    "   \n",
    "            \n",
    "    \n",
    "    minidict_g={\"VorlageNR\":gesch_nr, \"Einreichedatum\":einger_am, \"Link Vorstoss-PDF\":url_v_pdf,}\n",
    "    for key, value in minidict_g.items():\n",
    "        if value == '':\n",
    "            minidict_g[key] = 'NaN'  #hier schaue ich noch, dass ich die Leeren Zeilen mit NAN ersetzten kann.\n",
    "        else:\n",
    "            minidict_g[key] = value\n",
    "            \n",
    "    eingang_list.append(minidict_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g=pd.DataFrame(eingang_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Das Datum muss noch als solches lesbar gemacht werden\n",
    "df_g[\"Einreichedatum\"] =  pd.to_datetime(df_g[\"Einreichedatum\"], format='%d.%m.%Y') #verwandle string in datum\n",
    "df_g[\"VorlageNR\"] =df_g[\"VorlageNR\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g.to_csv(\"KRFrames/df_g_LinkszuPDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g=pd.read_csv(\"KRFrames/df_g_LinkszuPDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_g.sort_values(\"Einreichedatum\").head(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PDFs der Vorstösse runterladen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in tqdm(df_g[\"Link Vorstoss-PDF\"]):\n",
    "    r = requests.get(\"https://kr-geschaefte.zug.ch\"+link, stream =True) #Das Stream braucht es, um mit dem Zip umgehen zu koennen\n",
    "    name = link.split(\"/\")[-1] #Der Computer kann mit \"/\" in einem Namen nicht umgehen, deshalb nehme ich die hier raus, und nehme nur den letzten Teil des NAmens.\n",
    "    with open(\"KRGeschPDF/\"+name, \"wb\") as f:\n",
    "        f.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. PDFs sind auf dem Rechner, nun lesbar machen und !Regex Baby!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nun will ich aus jedem PDF zum Einen die VorlagenNR rausziehen sowie Namen und Datum hier die Definition\n",
    "# ! Danke dem |$ am Schluss gibt es keinen Index-Error, wenn er kein Resultat findet.\n",
    "regex_vorlage= r\"VORLAGE.NR\\..(\\d*)\\.1|$\" #hier ziehe ich die Vorlagennummer raus. \n",
    "regex_datum = r\"VOM.(\\d+\\..\\w*.\\d{4})|$\" # hier gehe ich an das DAtum\n",
    "regex_name=r\"\\bVON(.*UND.*)\" #Hier muss ich noch überlegen, wie anders. Problem: zum Teil sind Namen einzeln zum teil mehr\n",
    "# Und irgendwie erkennt er die Zeilenende nicht.\n",
    "regex_name1= r\"\\bVON.(\\w*.\\w*\\b)\"\n",
    "regex_partei= r\"DER.(\\w*)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lösung online gefunden um aus dem PDF-Ordner eine Liste mit den Links herzustellen.\n",
    "pdf_files_list= [f for f in listdir(\"KRGeschPDF\") if isfile(join(\"KRGeschPDF\", f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!! ACHTUNG: zuerst mit einzelen testen. Möglicherweise findet er die Files nicht. \n",
    "dat_pdf_list=[]\n",
    "for dok in pdf_files_list:\n",
    "    mypdf = open(\"KRGeschPDF/\"+dok, mode='rb')\n",
    "    pdf_name = dok\n",
    "    pdf_document = PyPDF2.PdfFileReader(mypdf)\n",
    "    first_page = pdf_document.getPage(0)\n",
    "    front=first_page.extractText()\n",
    "    dat_p_ein= re.findall(regex_datum, front, re.IGNORECASE)[0] #Ich greiffe auf das Datum zu\n",
    "        # um zu verhindern, dass ich mehrer Daten und Vorlagen habe, sage ich mit [0] er soll das erste nehmen\n",
    "    vorl_p_nr= re.findall(regex_vorlage, front, re.IGNORECASE)[0] # Ich greiffe auf die Vorlagennummer zu (zum Zusammenfügen der Dataframes)\n",
    "    \n",
    "    minidict_pdf_dat={\"Einreichedatum\": dat_p_ein, \"VorlageNR\":vorl_p_nr, \"Filename\":pdf_name}\n",
    "    \n",
    "    dat_pdf_list.append(minidict_pdf_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p=pd.DataFrame(dat_pdf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p.sort_values(\"Einreichedatum\") #Stichproben haben gezeigt, dass die fehlerhaften Datumsangaben in GEschäftern sind,\n",
    "# Welche selber eigentlich schon ein Datum haben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p.to_csv(\"KRFrames/INFOSausPDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Zeit in Datetime umwandeln\n",
    "schwierigkeit: wie bringe ich das deutsche Zeitformat in englisches. Mache ich es falsch oder gibts wieder probleme mit den Grossbuchstaben der Zeitformate? Hatten wir windowsuser auch schon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p=pd.read_csv(\"KRFrames/INFOSausPDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_p.sort_values(\"Einreichedatum\").tail(180) #Schschsch habe rund 10% ohne Datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locale.setlocale(locale.LC_ALL, 'de_DE')\n",
    "df_p[\"Einreichedatum\"] = pd.to_datetime(df_p[\"Einreichedatum\"], format= \"%d. %B %Y\", errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df_p #Halleluia:-) habs doch noch geschafft. Und die wenigen, die falsch formiert sind, werden nicht auffallen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p.to_csv(\"KRFrames/KonvertierteDatenformate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p=pd.read_csv(\"KRFrames/KonvertierteDatenformate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nun noch ohne.0 hinten bei der VorlageNR. Ah es ist ein Float. Kann es also zu int oder str machen\n",
    "df_p[\"VorlageNR\"]=df_p[\"VorlageNR\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting(elem):\n",
    "    elem = elem.split('.')[0].strip()\n",
    "    return elem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p[\"VorlageNR\"]=df_p[\"VorlageNR\"].apply(splitting) # So, nun sind die .0 weg. Mal schauen. Das String-Format reicht wohl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_p[\"Unnamed: 0\"] \n",
    "del df_p[\"Unnamed: 0.1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ps=df_p.rename(columns={\"Filename\": \"Link Vorstoss-PDF\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ps.to_csv(\"KRFrames/df_p_Datum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Ein Dataframe machen, mit den PDF-Dokumentennamen\n",
    "- splitting funktion schreiben\n",
    "- auf Spalte anwenden\n",
    "- neu abspeichern "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splittpdf(elem):\n",
    "    elem = elem.split('/')[-1].strip()\n",
    "    return elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g[\"Link Vorstoss-PDF\"]=df_g[\"Link Vorstoss-PDF\"].apply(splittpdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g.to_csv(\"KRFrames/df_g_Datum_mit_PDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Nun zusammenfügen der beiden Daten-Dataframes anhand der PDF-Namen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g1=pd.read_csv(\"KRFrames/df_g_Datum_mit_PDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p1=pd.read_csv(\"KRFrames/df_p_Datum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dat_max=pd.merge(df_g1, df_p1, how=\"inner\",on= \"Link Vorstoss-PDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>VorlageNR_x</th>\n",
       "      <th>Einreichedatum_x</th>\n",
       "      <th>Link Vorstoss-PDF</th>\n",
       "      <th>Unnamed: 0_y</th>\n",
       "      <th>Einreichedatum_y</th>\n",
       "      <th>VorlageNR_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>802</td>\n",
       "      <td>926</td>\n",
       "      <td>926</td>\n",
       "      <td>1535</td>\n",
       "      <td>2007-05-07</td>\n",
       "      <td>pdoc_1715_1.pdf</td>\n",
       "      <td>829</td>\n",
       "      <td>2007-05-07</td>\n",
       "      <td>1535.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>709</td>\n",
       "      <td>826</td>\n",
       "      <td>826</td>\n",
       "      <td>1711</td>\n",
       "      <td>2008-07-21</td>\n",
       "      <td>12813.pdf</td>\n",
       "      <td>18</td>\n",
       "      <td>2008-07-21</td>\n",
       "      <td>1711.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>697</td>\n",
       "      <td>813</td>\n",
       "      <td>813</td>\n",
       "      <td>1731</td>\n",
       "      <td>2008-09-29</td>\n",
       "      <td>12876.pdf</td>\n",
       "      <td>30</td>\n",
       "      <td>2008-09-29</td>\n",
       "      <td>1731.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>665</td>\n",
       "      <td>781</td>\n",
       "      <td>781</td>\n",
       "      <td>1772</td>\n",
       "      <td>2009-01-15</td>\n",
       "      <td>12978.pdf</td>\n",
       "      <td>62</td>\n",
       "      <td>2009-01-15</td>\n",
       "      <td>1772.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>663</td>\n",
       "      <td>779</td>\n",
       "      <td>779</td>\n",
       "      <td>1777</td>\n",
       "      <td>2009-01-29</td>\n",
       "      <td>12996.pdf</td>\n",
       "      <td>64</td>\n",
       "      <td>2009-01-29</td>\n",
       "      <td>1777.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>323</td>\n",
       "      <td>370</td>\n",
       "      <td>370</td>\n",
       "      <td>2462</td>\n",
       "      <td>2014-11-30</td>\n",
       "      <td>14833_2462_1_Belastungsprogramm.pdf</td>\n",
       "      <td>384</td>\n",
       "      <td>2014-11-30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>324</td>\n",
       "      <td>371</td>\n",
       "      <td>371</td>\n",
       "      <td>2461</td>\n",
       "      <td>2014-11-30</td>\n",
       "      <td>14832_2461_1_Entlastungsprogramm.pdf</td>\n",
       "      <td>383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>372</td>\n",
       "      <td>372</td>\n",
       "      <td>2460</td>\n",
       "      <td>2014-11-30</td>\n",
       "      <td>14831_2460_1_Steuergesetzrevision.pdf</td>\n",
       "      <td>382</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>329</td>\n",
       "      <td>376</td>\n",
       "      <td>376</td>\n",
       "      <td>2456</td>\n",
       "      <td>2014-11-30</td>\n",
       "      <td>14827_-2456_14827_Umfahrung_Unter%C3%A4geri.pdf</td>\n",
       "      <td>378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>327</td>\n",
       "      <td>374</td>\n",
       "      <td>374</td>\n",
       "      <td>2458</td>\n",
       "      <td>2014-11-30</td>\n",
       "      <td>14829_-2458_1_Verwaltung.pdf</td>\n",
       "      <td>380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0_x  Unnamed: 0.1  VorlageNR_x Einreichedatum_x  \\\n",
       "802           926           926         1535       2007-05-07   \n",
       "709           826           826         1711       2008-07-21   \n",
       "697           813           813         1731       2008-09-29   \n",
       "665           781           781         1772       2009-01-15   \n",
       "663           779           779         1777       2009-01-29   \n",
       "..            ...           ...          ...              ...   \n",
       "323           370           370         2462       2014-11-30   \n",
       "324           371           371         2461       2014-11-30   \n",
       "325           372           372         2460       2014-11-30   \n",
       "329           376           376         2456       2014-11-30   \n",
       "327           374           374         2458       2014-11-30   \n",
       "\n",
       "                                   Link Vorstoss-PDF  Unnamed: 0_y  \\\n",
       "802                                  pdoc_1715_1.pdf           829   \n",
       "709                                        12813.pdf            18   \n",
       "697                                        12876.pdf            30   \n",
       "665                                        12978.pdf            62   \n",
       "663                                        12996.pdf            64   \n",
       "..                                               ...           ...   \n",
       "323              14833_2462_1_Belastungsprogramm.pdf           384   \n",
       "324             14832_2461_1_Entlastungsprogramm.pdf           383   \n",
       "325            14831_2460_1_Steuergesetzrevision.pdf           382   \n",
       "329  14827_-2456_14827_Umfahrung_Unter%C3%A4geri.pdf           378   \n",
       "327                     14829_-2458_1_Verwaltung.pdf           380   \n",
       "\n",
       "    Einreichedatum_y  VorlageNR_y  \n",
       "802       2007-05-07       1535.0  \n",
       "709       2008-07-21       1711.0  \n",
       "697       2008-09-29       1731.0  \n",
       "665       2009-01-15       1772.0  \n",
       "663       2009-01-29       1777.0  \n",
       "..               ...          ...  \n",
       "323       2014-11-30          NaN  \n",
       "324              NaN          NaN  \n",
       "325              NaN          NaN  \n",
       "329              NaN          NaN  \n",
       "327              NaN          NaN  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_dat_max.sort_values(\"Einreichedatum_x\").head(100)  #So, jetzt sind zwar beide zusammen, aber noch nicht vereint\n",
    "#Jetzt noch irgendwie die beiden Einreichedaten miteinander ableichen/ergängen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Alle Dataframes zusammenfügen \n",
    "- Alle einlesen und auf die Unterseiten verweisen\n",
    "- eines nach dem andern anhängen\n",
    "- noch schön machen und kontrollieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen:\n",
    "df_v=pd.read_csv(\"KRFrames/df_v_Hauptseiten\") #Alle Vorstösse mit Infos mit Titel und Nummer der Page mit allen Geschäften\n",
    "df_dat=pd.read_csv(\"KRFrames/df_p_Datum\")# Frame mit allen Zeitangaben(Datum)(oben)\n",
    "df_np=pd.read_csv(\"KRFrames/Frame_mit_Namen_und_Parteien\")# Aus File \"02 Namen aus Geschäftsnamen...\" Alle Namen und Parteien\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  zuerst vorputzen\n",
    "df_v1 = df_v[[\"VorlageNR\", \"Geschäft\"]].copy()\n",
    "df_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dat[\"VorlageNR\"] = df_dat[\"VorlageNR\"].astype(str) #da ich im anderen Frame die Floats nicht in int ändern kann\n",
    "# mache ich alle zu str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dat[\"VorlageNR\"] = df_dat[\"VorlageNR\"].apply(splitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_napa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v1[\"VorlageNR\"]=df_v1[\"VorlageNR\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nun zusammenfügen\n",
    "df_alles=pd.merge(df_v1, df_dat, how=\"inner\",on= \"VorlageNR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_np[\"VorlageNR\"]=df_np[\"VorlageNR\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alles=pd.merge(df_alles, df_np, how=\"left\", on=\"VorlageNR\")\n",
    "df_alles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_alles[\"Unnamed: 0\"]\n",
    "del df_alles[\"Unnamed: 0.1\"]\n",
    "del df_alles [\"Unnamed: 0.1.1\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alles\n",
    "# Irgendwas lief schief!!!!! ich habe viel zu wenig Reihen und WEichelt ist nicht drin und auch sonst fehlen daten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alles # Irgendwie heats ein Durenand gegeben. Muss ich ein ander Mal anschauen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_alles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XX Zum Resultat hier mal das Dataframe der Hauptseite sowie der Unterseiten zusammenfügen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mit_dat=pd.merge(df_a, df_g, how=\"left\", on=\"GeschäftsNR\") #ich verbinde die beiden DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nun will ich noch das Datum zum Idex machen\n",
    "df_mit_dat.set_index(\"Einreichedatum\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mit_dat.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ein erstes Ergebnis = ab 2013 alle  Vorstösse\n",
    "# ACHTUNG das stimmt ja so gar nicht, da bei mehreren Personen\n",
    "# auch mehrere Einreichungen verzeichnet werden!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nun will ich ein erstes Mal in die DAten schauen, zumindest ab 2013 - ob es ein Muster beim Einreichen gibt.\n",
    "#DAzu krame ich jetzt alle Vorstösse raus\n",
    "\n",
    "df_vo_all=df_mit_dat[{\"Art des Geschäfts\" : [\"Motion\",\"Interpellation\",\"Postulat\",\"Kleine Anfrage\"] }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mit_dat[\"Art des Geschäfts\"][\"GeschäftsNR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vo_all[\"2013\":].resample(\"SMS\").count().plot(figsize=(8,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regex Baby! \n",
    "### Ich versuche mit Regex in Pandas an die Namen zu kommen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nun versuche ich mit Regex an die einzelnen Namen zu kommen.\n",
    "regex_n=r\"\\bvon(.*und.\\w*.\\w*\\b)\"\n",
    "regex_n2= r\"^(\\w*.\\w*\\b)\\,.(\\w*.\\w*\\b)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n1=df_a['Geschäft'].str.extract(regex_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
