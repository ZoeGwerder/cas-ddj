{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import requests, zipfile, io #zum abspeichern von PDFs\n",
    "from tqdm import tqdm # Anzeigen des aktuellen Ladestandes\n",
    "import PyPDF2\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import locale #für das deutsche Zeitformat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. URL von allen Hauptseiten holen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alle urls und infos der Hauptseiten holen.\n",
    "url = \"https://kr-geschaefte.zug.ch/gast/geschaefte?commit=Filtern&geschaeft_filter%5Babgeschlossen_bis%5D=&geschaeft_filter%5Babgeschlossen_von%5D=&geschaeft_filter%5Barten_refs%5D%5B%5D=&geschaeft_filter%5Beingereicht_bis%5D=&geschaeft_filter%5Beingereicht_von%5D=&geschaeft_filter%5Bfrist_bis%5D=&geschaeft_filter%5Bhistorische_staende_refs%5D%5B%5D=&geschaeft_filter%5Bkommissionen_refs%5D%5B%5D=&geschaeft_filter%5Bstaende_refs%5D%5B%5D=&geschaeft_filter%5Bstatus_ids%5D%5B%5D=haengig&geschaeft_filter%5Bstatus_ids%5D%5B%5D=abgeschlossen&geschaeft_filter%5Bstatus_ids%5D%5B%5D=&geschaeft_filter%5Btitel%5D=&geschaeft_filter%5Bzustaendig_refs%5D%5B%5D=&page=\"\n",
    "\n",
    "alle_seiten = []\n",
    "for seite in range(1,41):\n",
    "    r=requests.get(url+str(seite))\n",
    "    soup = BeautifulSoup(r.text,\"html.parser\")\n",
    "    \n",
    "    tr_list=soup.find_all(\"tr\")[2:] #erst ab der Position 2 sind die Daten relevant.\n",
    "    \n",
    "    for element in tr_list:\n",
    "        td_list = element.find_all(\"td\")\n",
    "        vorlag_nr=td_list[0].text\n",
    "        href = td_list[0].find(\"a\")[\"href\"]\n",
    "        text = td_list[1].text\n",
    "        stand = td_list[2].text\n",
    "        zustaendig = td_list[3].text\n",
    "        geschaeft_art = td_list[4].text\n",
    "        status = td_list[5].text\n",
    "        \n",
    "        mini_dict = {\"VorlageNR\":vorlag_nr,\"url\":href,\"Geschäft\":text, \"Stand\":stand, \"Zuständigkeit\":zustaendig, \"Art des Geschäfts\": geschaeft_art, \"Status\":status}\n",
    "\n",
    "        alle_seiten.append(mini_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(alle_seiten)\n",
    "df_a=pd.DataFrame(alle_seiten)\n",
    "# Die Geschäftsnummer zur Zahl machen. \n",
    "df_a[\"VorlageNR\"] = df_a[\"VorlageNR\"].astype(int) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Selektion: Fokus auf Vorstösse\n",
    "So will ich eine allzu grosse pdf-Schwemme verhindern.\n",
    "Die Idee: nur jene Geschäfte auf den PC ziehen, die auch relevant sind für die Auswertung. \n",
    "Also nur Vorstösse. Mich so bis zu den PDF's vorkämpfen, um auch hier nur jene auf meinem Rechner zu haben, \n",
    "die ich wirklich auf meinem Rechner will."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#hier mache ich eine Liste, die nur aus denjenigen URLs besteht, die Vorstösse sind. \n",
    "\n",
    "list_of_vorstoss=[\"Motion\",\"Interpellation\",\"Postulat\",\"Kleine Anfrage\", \"Initiative\"]\n",
    "df_v=df_a[df_a[\"Art des Geschäfts\"].isin (list_of_vorstoss)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v #hier habe ich nun alle Vorstösse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_v=df_v.reset_index()#Ich will überall nun denselben Index. deshalb nur soviel, wie ich Zeilen habe\n",
    "df_v.to_csv(\"KRFrames/df_v_Hauptseiten\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Eine Liste aus allen Geschäfts-URLs machen (um später auf diese zuzugreiffen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_liste_ganz=[]\n",
    "url_anfang_original=\"https://kr-geschaefte.zug.ch\"\n",
    "for element in df_v[\"url\"]:\n",
    "    url_liste_ganz.append(url_anfang_original+element)\n",
    "#diese werden zusammengefügt aus dem Anfang der Adresse sowie dem Geschäfts-URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(url_liste_ganz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Die einzelnen Geschäfte aufrufen und Infos rausholen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -> Einschub: ich will speichern und mit diesen Daten dann arbeiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#habe nun alle Seiten der Geschäfte auf meinem Rechner gespeichert. \n",
    "number = 0\n",
    "for page in url_liste_ganz:\n",
    "    page_content = requests.get(page)\n",
    "    page_content = page_content.text\n",
    "    with open(\"Geschaeft\"+str(number)+\".html\", \"w\") as file:\n",
    "        file.write(page_content)\n",
    "        file.close()\n",
    "    number +=1\n",
    "    #Es sind nun exakt so viele Seiten auf meinem Rechner, wie das DataFrame oben Zeilen anzeigt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <-Einschub-Ende. Ich habe es geschafft, das zu speichern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nun muss ich den Code ändern, sodass ich nicht mehr online zugreiffe sondern über meinen Ordner.\n",
    "#hier nun die Liste der Zugriffe.\n",
    "geschaefts_liste=[]#####ACHTUNG ich mache den RANGE kleiner, um weniger GEschäfte zu erhalten.\n",
    "\n",
    "for seite_g in range(0,1220): #Range für alle Geschäfte wäre 1219!\n",
    "    gesch= \"KRhtml/Geschaeft\"+str(seite_g)+\".html\"\n",
    "    geschaefts_liste.append(gesch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(geschaefts_liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geschaefts_liste[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Zugang zu den PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ich musste rausfinden, bei welchen Files ich nicht auf die Nummer 1 zugreiffen kann. \n",
    "*Siehe File: \"Falsche Files rausfinden - code anpassen\"* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hier  habe ich mich entschieden, auf den Zugriff der Namen zu verzichten, und dies einheitlich über die PDFs zu lösen.\n",
    "#Nun seite für Seite abrufen und in einem neuen Minidict unterbringen\n",
    "eingang_list=[]\n",
    "\n",
    "\n",
    "for geschaeft in geschaefts_liste:\n",
    "    file = open(geschaeft, 'r')\n",
    "    text = file.read()\n",
    "    soup_g = BeautifulSoup(text, 'html.parser')\n",
    "    tr_g_list=soup_g.find_all(\"tr\")\n",
    "    td_g_list=tr_g_list[-1].find_all(\"td\")#hier gehe ich zum Dokument.\n",
    "    gesch_nr = tr_g_list[-1].find_all(\"td\")[0].text\n",
    "    einger_am = tr_g_list[1].find_all(\"td\")[0].text   \n",
    "   \n",
    "   \n",
    "     #Da es zum Teil Referenzen hat und dadurch ein anderer Ort abgegriffen werden muss, muss ich varieren.\n",
    "    \n",
    "    if td_g_list[-1].find_all(\"a\")[0].text== \"1\": #Ich brauche immer das Dokument 1. \n",
    "        url_v_pdf = td_g_list[-1].find(\"a\")[\"href\"]\n",
    "    \n",
    "    elif td_g_list[-1].find_all(\"a\")[0].text== \"2\": #bei älteren GEschäften sind es Bericht&Anträge\n",
    "        url_v_pdf = td_g_list[-1].find(\"a\")[\"href\"]   \n",
    "    else: \n",
    "        td_g_list[-1].find_all(\"a\")[0].text== \"3\"\n",
    "        url_v_pdf = td_g_list[-1].find(\"a\")[\"href\"]\n",
    "   \n",
    "            \n",
    "    \n",
    "    minidict_g={\"VorlageNR\":gesch_nr, \"Einreichedatum\":einger_am, \"Link Vorstoss-PDF\":url_v_pdf,}\n",
    "    for key, value in minidict_g.items():\n",
    "        if value == '':\n",
    "            minidict_g[key] = 'NaN'  #hier schaue ich noch, dass ich die Leeren Zeilen mit NAN ersetzten kann.\n",
    "        else:\n",
    "            minidict_g[key] = value\n",
    "            \n",
    "    eingang_list.append(minidict_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g=pd.DataFrame(eingang_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Das Datum muss noch als solches lesbar gemacht werden\n",
    "df_g[\"Einreichedatum\"] =  pd.to_datetime(df_g[\"Einreichedatum\"], format='%d.%m.%Y') #verwandle string in datum\n",
    "df_g[\"VorlageNR\"] =df_g[\"VorlageNR\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g.to_csv(\"KRFrames/df_g_LinkszuPDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g=pd.read_csv(\"KRFrames/df_g_LinkszuPDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PDFs der Vorstösse runterladen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in tqdm(df_g[\"Link Vorstoss-PDF\"]):\n",
    "    r = requests.get(\"https://kr-geschaefte.zug.ch\"+link, stream =True) #Das Stream braucht es, um mit dem Zip umgehen zu koennen\n",
    "    name = link.split(\"/\")[-1] #Der Computer kann mit \"/\" in einem Namen nicht umgehen, deshalb nehme ich die hier raus, und nehme nur den letzten Teil des NAmens.\n",
    "    with open(\"KRGeschPDF/\"+name, \"wb\") as f:\n",
    "        f.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. PDFs sind auf dem Rechner, nun lesbar machen und !Regex Baby!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nun will ich aus jedem PDF zum Einen die VorlagenNR rausziehen sowie Namen und Datum hier die Definition\n",
    "# ! Danke dem |$ am Schluss gibt es keinen Index-Error, wenn er kein Resultat findet.\n",
    "regex_vorlage= r\"VORLAGE.NR\\..(\\d*)\\.1|$\" #hier ziehe ich die Vorlagennummer raus. \n",
    "regex_datum = r\"VOM.(\\d+\\..\\w*.\\d{4})|$\" # hier gehe ich an das DAtum\n",
    "regex_name=r\"\\bVON(.*UND.*)\" #Hier muss ich noch überlegen, wie anders. Problem: zum Teil sind Namen einzeln zum teil mehr\n",
    "# Und irgendwie erkennt er die Zeilenende nicht.\n",
    "regex_name1= r\"\\bVON.(\\w*.\\w*\\b)\"\n",
    "regex_partei= r\"DER.(\\w*)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lösung online gefunden um aus dem PDF-Ordner eine Liste mit den Links herzustellen.\n",
    "pdf_files_list= [f for f in listdir(\"KRGeschPDF\") if isfile(join(\"KRGeschPDF\", f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pdf_files_list) #Ich habe ja die PDFs ignoriert, zu welchen ich auf Grund der Referenz keine PDF-Links hatte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!! ACHTUNG: zuerst mit einzelen testen. Möglicherweise findet er die Files nicht. \n",
    "dat_pdf_list=[]\n",
    "for dok in pdf_files_list:\n",
    "    mypdf = open(\"KRGeschPDF/\"+dok, mode='rb')\n",
    "    pdf_name = dok\n",
    "    pdf_document = PyPDF2.PdfFileReader(mypdf)\n",
    "    first_page = pdf_document.getPage(0)\n",
    "    front=first_page.extractText()\n",
    "    dat_p_ein= re.findall(regex_datum, front, re.IGNORECASE)[0] #Ich greiffe auf das Datum zu\n",
    "        # um zu verhindern, dass ich mehrer Daten und Vorlagen habe, sage ich mit [0] er soll das erste nehmen\n",
    "    vorl_p_nr= re.findall(regex_vorlage, front, re.IGNORECASE)[0] # Ich greiffe auf die Vorlagennummer zu (zum Zusammenfügen der Dataframes)\n",
    "    \n",
    "    \n",
    "    minidict_pdf_dat={\"Einreichedatum\": dat_p_ein, \"VorlageNR\":vorl_p_nr, \"Filename\":pdf_name}\n",
    "    \n",
    "    dat_pdf_list.append(minidict_pdf_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p=pd.DataFrame(dat_pdf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p.sort_values(\"Einreichedatum\") #Stichproben haben gezeigt, dass die fehlerhaften Datumsangaben in GEschäftern sind,\n",
    "# Welche selber meist schon ein Datum haben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p.to_csv(\"KRFrames/INFOSausPDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p[\"Filename\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p=pd.read_csv(\"KRFrames/INFOSausPDF\")\n",
    "df_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Zeit in Datetime umwandeln\n",
    "schwierigkeit: wie bringe ich das deutsche Zeitformat in englisches. Mache ich es falsch oder gibts wieder probleme mit den Grossbuchstaben der Zeitformate? Hatten wir windowsuser auch schon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p=pd.read_csv(\"KRFrames/INFOSausPDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locale.setlocale(locale.LC_ALL, 'de_DE') # hier die Sprachwahl\n",
    "df_p[\"Einreichedatum\"] = pd.to_datetime(df_p[\"Einreichedatum\"], format= \"%d. %B %Y\", errors='coerce') #Angabe des Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df_p #Halleluia:-) habs doch noch geschafft. Und die wenigen, die falsch formiert sind, werden nicht auffallen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p.to_csv(\"KRFrames/KonvertierteDatenformate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p=pd.read_csv(\"KRFrames/KonvertierteDatenformate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nun noch ohne.0 hinten bei der VorlageNR. Ah es ist ein Float. Kann es also zu int oder str machen\n",
    "df_p[\"VorlageNR\"]=df_p[\"VorlageNR\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting(elem):\n",
    "    elem = elem.split('.')[0].strip()\n",
    "    return elem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p[\"VorlageNR\"]=df_p[\"VorlageNR\"].apply(splitting) # So, nun sind die .0 weg. Mal schauen. Das String-Format reicht wohl\n",
    "del df_p[\"Unnamed: 0\"] # die beiden Spalten entfernen\n",
    "del df_p[\"Unnamed: 0.1\"]\n",
    "df_ps=df_p.rename(columns={\"Filename\": \"Link Vorstoss-PDF\"}) #Spalte gleich benennen wie im anderen Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ps.to_csv(\"KRFrames/df_p_Datum\") # und speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Einreichedatum</th>\n",
       "      <th>VorlageNR</th>\n",
       "      <th>Link Vorstoss-PDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2007-09-17</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>12487_1584.1_motion.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2007-09-18</td>\n",
       "      <td>1589.0</td>\n",
       "      <td>12493_1589_1_motion.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2007-12-06</td>\n",
       "      <td>1616.0</td>\n",
       "      <td>12562_1616_1_motion.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2008-01-31</td>\n",
       "      <td>1635.0</td>\n",
       "      <td>12611_1635_1motion.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2008-02-21</td>\n",
       "      <td>1644.0</td>\n",
       "      <td>12634_1644_1_interpellation.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1088</td>\n",
       "      <td>1088</td>\n",
       "      <td>2005-08-04</td>\n",
       "      <td>1362.0</td>\n",
       "      <td>pdoc_972_1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1089</td>\n",
       "      <td>1089</td>\n",
       "      <td>2005-08-12</td>\n",
       "      <td>1363.0</td>\n",
       "      <td>pdoc_977_1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>1090</td>\n",
       "      <td>2005-06-23</td>\n",
       "      <td>1364.0</td>\n",
       "      <td>pdoc_978_1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1091</td>\n",
       "      <td>1091</td>\n",
       "      <td>2005-08-26</td>\n",
       "      <td>1365.0</td>\n",
       "      <td>pdoc_984_1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1092</td>\n",
       "      <td>1092</td>\n",
       "      <td>2005-09-16</td>\n",
       "      <td>1374.0</td>\n",
       "      <td>pdoc_994_1.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1093 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 Einreichedatum  VorlageNR                Link Vorstoss-PDF\n",
       "0              0     2007-09-17     1584.0          12487_1584.1_motion.pdf\n",
       "1              1     2007-09-18     1589.0          12493_1589_1_motion.pdf\n",
       "2              2     2007-12-06     1616.0          12562_1616_1_motion.pdf\n",
       "3              3     2008-01-31     1635.0           12611_1635_1motion.pdf\n",
       "4              4     2008-02-21     1644.0  12634_1644_1_interpellation.pdf\n",
       "...          ...            ...        ...                              ...\n",
       "1088        1088     2005-08-04     1362.0                   pdoc_972_1.pdf\n",
       "1089        1089     2005-08-12     1363.0                   pdoc_977_1.pdf\n",
       "1090        1090     2005-06-23     1364.0                   pdoc_978_1.pdf\n",
       "1091        1091     2005-08-26     1365.0                   pdoc_984_1.pdf\n",
       "1092        1092     2005-09-16     1374.0                   pdoc_994_1.pdf\n",
       "\n",
       "[1093 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ps=pd.read_csv(\"KRFrames/df_p_Datum\")\n",
    "df_ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Ein Dataframe machen, mit den PDF-Dokumentennamen\n",
    "- splitting funktion schreiben\n",
    "- auf Spalte anwenden\n",
    "- neu abspeichern "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splittpdf(elem):\n",
    "    elem = elem.split('/')[-1].strip()\n",
    "    return elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g[\"Link Vorstoss-PDF\"]=df_g[\"Link Vorstoss-PDF\"].apply(splittpdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g.to_csv(\"KRFrames/df_g_Datum_mit_PDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Nun zusammenfügen der beiden Daten-Dataframes anhand der PDF-Namen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g1=pd.read_csv(\"KRFrames/df_g_Datum_mit_PDF\")\n",
    "df_p1=pd.read_csv(\"KRFrames/df_p_Datum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dat_max=pd.merge(df_g1, df_p1, how=\"left\",on= \"Link Vorstoss-PDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dat_max.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dat_max.sort_values(\"Einreichedatum_x\").tail(100)  #So, jetzt sind zwar beide zusammen, aber noch nicht vereint\n",
    "#Jetzt noch irgendwie die beiden Einreichedaten miteinander ableichen/ergängen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 die Datenspalten zusammenbekommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hier füge ich sie zusammen\n",
    "df_dat_zus=df_dat_max.Einreichedatum_x.combine_first(df_dat_max.Einreichedatum_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dat_max['Einreichedatum'] = df_dat_zus # hier füge ich die neu enstandene \"Series\" dem Dataframe an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datum=df_dat_max[[\"Unnamed: 0_x\",\"VorlageNR_x\", \"Einreichedatum\", \"Link Vorstoss-PDF\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datum[\"Einreichedatum\"].sort_values().tail(30)\n",
    "                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datum.to_csv(\"KRFrames/df_datum_ALLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Alle Dataframes zusammenfügen \n",
    "- Alle einlesen und auf die Unterseiten verweisen\n",
    "- eines nach dem andern anhängen\n",
    "- noch schön machen und kontrollieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen:\n",
    "df_v=pd.read_csv(\"KRFrames/df_v_Hauptseiten\") #Alle Vorstösse mit Infos mit Titel und Nummer der Page mit allen Geschäften\n",
    "df_dat_all=pd.read_csv(\"KRFrames/df_datum_ALLE\")# Frame mit allen Zeitangaben(Datum)(oben)\n",
    "df_np=pd.read_csv(\"KRFrames/Frame_Namen_Partei_endversion\")# Aus File \"02 Namen aus Geschäftsnamen...\" Alle Namen und Parteien\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>VorlageNR</th>\n",
       "      <th>Einreichedatum</th>\n",
       "      <th>Link Vorstoss-PDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1219</td>\n",
       "      <td>1219</td>\n",
       "      <td>1219</td>\n",
       "      <td>81</td>\n",
       "      <td>2007-04-10</td>\n",
       "      <td>pdoc_1705_1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1217</td>\n",
       "      <td>1217</td>\n",
       "      <td>1217</td>\n",
       "      <td>304</td>\n",
       "      <td>2003-05-27</td>\n",
       "      <td>pdoc_50_1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1216</td>\n",
       "      <td>1216</td>\n",
       "      <td>1216</td>\n",
       "      <td>666</td>\n",
       "      <td>2002-06-06</td>\n",
       "      <td>pdoc_55_1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1215</td>\n",
       "      <td>1215</td>\n",
       "      <td>1215</td>\n",
       "      <td>762</td>\n",
       "      <td>2005-10-31</td>\n",
       "      <td>pdoc_1047_1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1214</td>\n",
       "      <td>1214</td>\n",
       "      <td>1214</td>\n",
       "      <td>801</td>\n",
       "      <td>2006-08-22</td>\n",
       "      <td>pdoc_1440_1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3014</td>\n",
       "      <td>2019-09-26</td>\n",
       "      <td>3014-1-16159_Geschwindigkeitskontrollen-2-0.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3017</td>\n",
       "      <td>2019-10-06</td>\n",
       "      <td>3017-1-16165_Frauenwahl-stimmrecht_Feier.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3018</td>\n",
       "      <td>2019-10-07</td>\n",
       "      <td>3018-1-16166_Praktikum.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3019</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>3019-1-16167_Chancengleichheit.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3020</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>3020-1-16168_Racial-Profiling.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1220 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0_x  VorlageNR Einreichedatum  \\\n",
       "1219        1219          1219         81     2007-04-10   \n",
       "1217        1217          1217        304     2003-05-27   \n",
       "1216        1216          1216        666     2002-06-06   \n",
       "1215        1215          1215        762     2005-10-31   \n",
       "1214        1214          1214        801     2006-08-22   \n",
       "...          ...           ...        ...            ...   \n",
       "4              4             4       3014     2019-09-26   \n",
       "3              3             3       3017     2019-10-06   \n",
       "2              2             2       3018     2019-10-07   \n",
       "1              1             1       3019     2019-10-11   \n",
       "0              0             0       3020     2019-10-11   \n",
       "\n",
       "                                    Link Vorstoss-PDF  \n",
       "1219                                  pdoc_1705_1.pdf  \n",
       "1217                                    pdoc_50_1.pdf  \n",
       "1216                                    pdoc_55_1.pdf  \n",
       "1215                                  pdoc_1047_1.pdf  \n",
       "1214                                  pdoc_1440_1.pdf  \n",
       "...                                               ...  \n",
       "4     3014-1-16159_Geschwindigkeitskontrollen-2-0.pdf  \n",
       "3        3017-1-16165_Frauenwahl-stimmrecht_Feier.pdf  \n",
       "2                          3018-1-16166_Praktikum.pdf  \n",
       "1                  3019-1-16167_Chancengleichheit.pdf  \n",
       "0                   3020-1-16168_Racial-Profiling.pdf  \n",
       "\n",
       "[1220 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dat_all.sort_values(\"VorlageNR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VorlageNR             int64\n",
       "Geschäft             object\n",
       "Zuständigkeit        object\n",
       "Art des Geschäfts    object\n",
       "Status               object\n",
       "url                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  zuerst vorputzen\n",
    "df_v1 = df_v[[\"VorlageNR\", \"Geschäft\", \"Zuständigkeit\", \"Art des Geschäfts\", \"Status\", \"url\"]].copy()\n",
    "df_v1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dat_all=df_dat_all.rename(columns={\"VorlageNR_x\": \"VorlageNR\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0            int64\n",
       "Unnamed: 0_x          int64\n",
       "VorlageNR             int64\n",
       "Einreichedatum       object\n",
       "Link Vorstoss-PDF    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dat_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Nun zusammenfügen\n",
    "df_alles=pd.merge(df_v1, df_dat_all, how=\"inner\",on= \"VorlageNR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VorlageNR</th>\n",
       "      <th>Geschäft</th>\n",
       "      <th>Zuständigkeit</th>\n",
       "      <th>Art des Geschäfts</th>\n",
       "      <th>Status</th>\n",
       "      <th>url</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>Einreichedatum</th>\n",
       "      <th>Link Vorstoss-PDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3020</td>\n",
       "      <td>Postulat von Luzian Franzini und Esther Haas b...</td>\n",
       "      <td>Sicherheitsdirektion</td>\n",
       "      <td>Postulat</td>\n",
       "      <td>hängig</td>\n",
       "      <td>/gast/geschaefte/2008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>3020-1-16168_Racial-Profiling.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3019</td>\n",
       "      <td>Motion von Luzian Franzini, Rita Hofer, Tabea ...</td>\n",
       "      <td>Direktion des Innern</td>\n",
       "      <td>Motion</td>\n",
       "      <td>hängig</td>\n",
       "      <td>/gast/geschaefte/2007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>3019-1-16167_Chancengleichheit.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3018</td>\n",
       "      <td>Interpellation von Fabio Iten, Laura Dittli un...</td>\n",
       "      <td>Volkswirtschaftsdirektion</td>\n",
       "      <td>Interpellation</td>\n",
       "      <td>hängig</td>\n",
       "      <td>/gast/geschaefte/2006</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-07</td>\n",
       "      <td>3018-1-16166_Praktikum.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3017</td>\n",
       "      <td>Postulat von Tabea Zimmermann Gibson, Stéphani...</td>\n",
       "      <td>Direktion des Innern</td>\n",
       "      <td>Postulat</td>\n",
       "      <td>hängig</td>\n",
       "      <td>/gast/geschaefte/2005</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-06</td>\n",
       "      <td>3017-1-16165_Frauenwahl-stimmrecht_Feier.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3014</td>\n",
       "      <td>Interpellation der SVP-Fraktion betreffend mob...</td>\n",
       "      <td>Sicherheitsdirektion</td>\n",
       "      <td>Interpellation</td>\n",
       "      <td>hängig</td>\n",
       "      <td>/gast/geschaefte/2002</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-09-26</td>\n",
       "      <td>3014-1-16159_Geschwindigkeitskontrollen-2-0.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>801</td>\n",
       "      <td>Motion von Hans Abicht betreffend Raumkonzept ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Motion</td>\n",
       "      <td>abgeschlossen</td>\n",
       "      <td>/gast/geschaefte/1333</td>\n",
       "      <td>1214</td>\n",
       "      <td>1214</td>\n",
       "      <td>2006-08-22</td>\n",
       "      <td>pdoc_1440_1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1141</td>\n",
       "      <td>762</td>\n",
       "      <td>Motion der erweiterten Justizprüfungskommissio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Motion</td>\n",
       "      <td>abgeschlossen</td>\n",
       "      <td>/gast/geschaefte/1331</td>\n",
       "      <td>1215</td>\n",
       "      <td>1215</td>\n",
       "      <td>2005-10-31</td>\n",
       "      <td>pdoc_1047_1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1142</td>\n",
       "      <td>666</td>\n",
       "      <td>Motion der Kommission Teilrevision Personalges...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Motion</td>\n",
       "      <td>abgeschlossen</td>\n",
       "      <td>/gast/geschaefte/1325</td>\n",
       "      <td>1216</td>\n",
       "      <td>1216</td>\n",
       "      <td>2002-06-06</td>\n",
       "      <td>pdoc_55_1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1143</td>\n",
       "      <td>304</td>\n",
       "      <td>Motion von Manuela Weichelt betreffend HIV-Prä...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Motion</td>\n",
       "      <td>abgeschlossen</td>\n",
       "      <td>/gast/geschaefte/1309</td>\n",
       "      <td>1217</td>\n",
       "      <td>1217</td>\n",
       "      <td>2003-05-27</td>\n",
       "      <td>pdoc_50_1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1144</td>\n",
       "      <td>81</td>\n",
       "      <td>Motion der vorberatenden Kommission betreffend...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Motion</td>\n",
       "      <td>abgeschlossen</td>\n",
       "      <td>/gast/geschaefte/1334</td>\n",
       "      <td>1219</td>\n",
       "      <td>1219</td>\n",
       "      <td>2007-04-10</td>\n",
       "      <td>pdoc_1705_1.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1145 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      VorlageNR                                           Geschäft  \\\n",
       "0          3020  Postulat von Luzian Franzini und Esther Haas b...   \n",
       "1          3019  Motion von Luzian Franzini, Rita Hofer, Tabea ...   \n",
       "2          3018  Interpellation von Fabio Iten, Laura Dittli un...   \n",
       "3          3017  Postulat von Tabea Zimmermann Gibson, Stéphani...   \n",
       "4          3014  Interpellation der SVP-Fraktion betreffend mob...   \n",
       "...         ...                                                ...   \n",
       "1140        801  Motion von Hans Abicht betreffend Raumkonzept ...   \n",
       "1141        762  Motion der erweiterten Justizprüfungskommissio...   \n",
       "1142        666  Motion der Kommission Teilrevision Personalges...   \n",
       "1143        304  Motion von Manuela Weichelt betreffend HIV-Prä...   \n",
       "1144         81  Motion der vorberatenden Kommission betreffend...   \n",
       "\n",
       "                  Zuständigkeit Art des Geschäfts         Status  \\\n",
       "0          Sicherheitsdirektion          Postulat         hängig   \n",
       "1          Direktion des Innern            Motion         hängig   \n",
       "2     Volkswirtschaftsdirektion    Interpellation         hängig   \n",
       "3          Direktion des Innern          Postulat         hängig   \n",
       "4          Sicherheitsdirektion    Interpellation         hängig   \n",
       "...                         ...               ...            ...   \n",
       "1140                        NaN            Motion  abgeschlossen   \n",
       "1141                        NaN            Motion  abgeschlossen   \n",
       "1142                        NaN            Motion  abgeschlossen   \n",
       "1143                        NaN            Motion  abgeschlossen   \n",
       "1144                        NaN            Motion  abgeschlossen   \n",
       "\n",
       "                        url  Unnamed: 0  Unnamed: 0_x Einreichedatum  \\\n",
       "0     /gast/geschaefte/2008           0             0     2019-10-11   \n",
       "1     /gast/geschaefte/2007           1             1     2019-10-11   \n",
       "2     /gast/geschaefte/2006           2             2     2019-10-07   \n",
       "3     /gast/geschaefte/2005           3             3     2019-10-06   \n",
       "4     /gast/geschaefte/2002           4             4     2019-09-26   \n",
       "...                     ...         ...           ...            ...   \n",
       "1140  /gast/geschaefte/1333        1214          1214     2006-08-22   \n",
       "1141  /gast/geschaefte/1331        1215          1215     2005-10-31   \n",
       "1142  /gast/geschaefte/1325        1216          1216     2002-06-06   \n",
       "1143  /gast/geschaefte/1309        1217          1217     2003-05-27   \n",
       "1144  /gast/geschaefte/1334        1219          1219     2007-04-10   \n",
       "\n",
       "                                    Link Vorstoss-PDF  \n",
       "0                   3020-1-16168_Racial-Profiling.pdf  \n",
       "1                  3019-1-16167_Chancengleichheit.pdf  \n",
       "2                          3018-1-16166_Praktikum.pdf  \n",
       "3        3017-1-16165_Frauenwahl-stimmrecht_Feier.pdf  \n",
       "4     3014-1-16159_Geschwindigkeitskontrollen-2-0.pdf  \n",
       "...                                               ...  \n",
       "1140                                  pdoc_1440_1.pdf  \n",
       "1141                                  pdoc_1047_1.pdf  \n",
       "1142                                    pdoc_55_1.pdf  \n",
       "1143                                    pdoc_50_1.pdf  \n",
       "1144                                  pdoc_1705_1.pdf  \n",
       "\n",
       "[1145 rows x 10 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_alles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_alles.to_csv(\"KRFrames/df_alles_ohne_Namen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alles_ganz=pd.merge(df_alles, df_np, how=\"left\", on=\"VorlageNR\")\n",
    "df_alles_ganz.sort_values(\"Einreichedatum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tuti=df_alles_ganz[[\"VorlageNR\",\"Geschäft\", \"Namenganz\", \"P\", \"Einreichedatum\", \"Link Vorstoss-PDF\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tuti #Wieso wird es nicht ergänzt. Der Fehler ist im File 02 Namen passiert. dort nachschauen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "df_tuti1=df_tuti.drop_duplicates(subset=['VorlageNR', 'Namenganz'], keep=False)\n",
    "# Obwohl mir nur von 30 Geschäften das Datum fehlt, explodiert dies, wenn es auf die Namen-Tabelle kommt.\n",
    "df_tuti1.sort_values(\"Einreichedatum\").tail(188)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tuti.to_csv(\"KRFrames/df_tuti_Ganzes_Frame\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten aus B&A mit falschen Zahlen\n",
    "Eine Lösung wäre, nochmals die Links zu den PDF auslesen und diese in zwei verschiedene Listen verpacken. \n",
    "Da die Datenmigration im Jahr 2000 war, schaue ich einfach mal die Zahlen ab 2005 an. Vo dort an, werden die meisten Geschäfte tatsächlich neu sein. \n",
    "## #Andere Variante: ich lasse die B&A einfach weg. Da gibt es eh keine verlässliche Daten. Mengenmässig.\n",
    "# Nun plotten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tuti = df_tuti.set_index('Einreichedatum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tuti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tuti.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
