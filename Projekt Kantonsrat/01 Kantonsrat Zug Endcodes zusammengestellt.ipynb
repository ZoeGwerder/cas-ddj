{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import requests, zipfile, io #zum abspeichern von PDFs\n",
    "from tqdm import tqdm # Anzeigen des aktuellen Ladestandes\n",
    "import PyPDF2\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import locale #für das deutsche Zeitformat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. URL von allen Hauptseiten holen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alle urls und infos der Hauptseiten holen.\n",
    "url = \"https://kr-geschaefte.zug.ch/gast/geschaefte?commit=Filtern&geschaeft_filter%5Babgeschlossen_bis%5D=&geschaeft_filter%5Babgeschlossen_von%5D=&geschaeft_filter%5Barten_refs%5D%5B%5D=&geschaeft_filter%5Beingereicht_bis%5D=&geschaeft_filter%5Beingereicht_von%5D=&geschaeft_filter%5Bfrist_bis%5D=&geschaeft_filter%5Bhistorische_staende_refs%5D%5B%5D=&geschaeft_filter%5Bkommissionen_refs%5D%5B%5D=&geschaeft_filter%5Bstaende_refs%5D%5B%5D=&geschaeft_filter%5Bstatus_ids%5D%5B%5D=haengig&geschaeft_filter%5Bstatus_ids%5D%5B%5D=abgeschlossen&geschaeft_filter%5Bstatus_ids%5D%5B%5D=&geschaeft_filter%5Btitel%5D=&geschaeft_filter%5Bzustaendig_refs%5D%5B%5D=&page=\"\n",
    "\n",
    "alle_seiten = []\n",
    "for seite in range(1,41):\n",
    "    r=requests.get(url+str(seite))\n",
    "    soup = BeautifulSoup(r.text,\"html.parser\")\n",
    "    \n",
    "    tr_list=soup.find_all(\"tr\")[2:] #erst ab der Position 2 sind die Daten relevant.\n",
    "    \n",
    "    for element in tr_list:\n",
    "        td_list = element.find_all(\"td\")\n",
    "        vorlag_nr=td_list[0].text\n",
    "        href = td_list[0].find(\"a\")[\"href\"]\n",
    "        text = td_list[1].text\n",
    "        stand = td_list[2].text\n",
    "        zustaendig = td_list[3].text\n",
    "        geschaeft_art = td_list[4].text\n",
    "        status = td_list[5].text\n",
    "        \n",
    "        mini_dict = {\"VorlageNR\":vorlag_nr,\"url\":href,\"Geschäft\":text, \"Stand\":stand, \"Zuständigkeit\":zustaendig, \"Art des Geschäfts\": geschaeft_art, \"Status\":status}\n",
    "\n",
    "        alle_seiten.append(mini_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(alle_seiten)\n",
    "df_a=pd.DataFrame(alle_seiten)\n",
    "# Die Geschäftsnummer zur Zahl machen. \n",
    "df_a[\"VorlageNR\"] = df_a[\"VorlageNR\"].astype(int) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Selektion: Fokus auf Vorstösse\n",
    "So will ich eine allzu grosse pdf-Schwemme verhindern.\n",
    "Die Idee: nur jene Geschäfte auf den PC ziehen, die auch relevant sind für die Auswertung. \n",
    "Also nur Vorstösse. Mich so bis zu den PDF's vorkämpfen, um auch hier nur jene auf meinem Rechner zu haben, \n",
    "die ich wirklich auf meinem Rechner will."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#hier mache ich eine Liste, die nur aus denjenigen URLs besteht, die Vorstösse sind. \n",
    "\n",
    "list_of_vorstoss=[\"Motion\",\"Interpellation\",\"Postulat\",\"Kleine Anfrage\", \"Initiative\"]\n",
    "df_v=df_a[df_a[\"Art des Geschäfts\"].isin (list_of_vorstoss)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v #hier habe ich nun alle Vorstösse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_v=df_v.reset_index()#Ich will überall nun denselben Index. deshalb nur soviel, wie ich Zeilen habe\n",
    "df_v.to_csv(\"KRFrames/df_v_Hauptseiten\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Eine Liste aus allen Geschäfts-URLs machen (um später auf diese zuzugreiffen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_liste_ganz=[]\n",
    "url_anfang_original=\"https://kr-geschaefte.zug.ch\"\n",
    "for element in df_v[\"url\"]:\n",
    "    url_liste_ganz.append(url_anfang_original+element)\n",
    "#diese werden zusammengefügt aus dem Anfang der Adresse sowie dem Geschäfts-URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(url_liste_ganz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Die einzelnen Geschäfte aufrufen und Infos rausholen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -> Einschub: ich will speichern und mit diesen Daten dann arbeiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#habe nun alle Seiten der Geschäfte auf meinem Rechner gespeichert. \n",
    "number = 0\n",
    "for page in url_liste_ganz:\n",
    "    page_content = requests.get(page)\n",
    "    page_content = page_content.text\n",
    "    with open(\"Geschaeft\"+str(number)+\".html\", \"w\") as file:\n",
    "        file.write(page_content)\n",
    "        file.close()\n",
    "    number +=1\n",
    "    #Es sind nun exakt so viele Seiten auf meinem Rechner, wie das DataFrame oben Zeilen anzeigt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <-Einschub-Ende. Ich habe es geschafft, das zu speichern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nun muss ich den Code ändern, sodass ich nicht mehr online zugreiffe sondern über meinen Ordner.\n",
    "#hier nun die Liste der Zugriffe.\n",
    "geschaefts_liste=[]#####ACHTUNG ich mache den RANGE kleiner, um weniger GEschäfte zu erhalten.\n",
    "\n",
    "for seite_g in range(0,1220): #Range für alle Geschäfte wäre 1219!\n",
    "    gesch= \"KRhtml/Geschaeft\"+str(seite_g)+\".html\"\n",
    "    geschaefts_liste.append(gesch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(geschaefts_liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geschaefts_liste[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Zugang zu den PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ich musste rausfinden, bei welchen Files ich nicht auf die Nummer 1 zugreiffen kann. \n",
    "*Siehe File: \"Falsche Files rausfinden - code anpassen\"* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hier  habe ich mich entschieden, auf den Zugriff der Namen zu verzichten, und dies einheitlich über die PDFs zu lösen.\n",
    "#Nun seite für Seite abrufen und in einem neuen Minidict unterbringen\n",
    "eingang_list=[]\n",
    "\n",
    "\n",
    "for geschaeft in geschaefts_liste:\n",
    "    file = open(geschaeft, 'r')\n",
    "    text = file.read()\n",
    "    soup_g = BeautifulSoup(text, 'html.parser')\n",
    "    tr_g_list=soup_g.find_all(\"tr\")\n",
    "    td_g_list=tr_g_list[-1].find_all(\"td\")#hier gehe ich zum Dokument.\n",
    "    gesch_nr = tr_g_list[-1].find_all(\"td\")[0].text\n",
    "    einger_am = tr_g_list[1].find_all(\"td\")[0].text   \n",
    "   \n",
    "   \n",
    "     #Da es zum Teil Referenzen hat und dadurch ein anderer Ort abgegriffen werden muss, muss ich varieren.\n",
    "    \n",
    "    if td_g_list[-1].find_all(\"a\")[0].text== \"1\": #Ich brauche immer das Dokument 1. \n",
    "        url_v_pdf = td_g_list[-1].find(\"a\")[\"href\"]\n",
    "    elif td_g_list[-1].find_all(\"a\")[0].text== \"2\": #bei älteren GEschäften sind es Bericht&Anträge\n",
    "        url_v_pdf = td_g_list[-1].find(\"a\")[\"href\"]   \n",
    "    else: \n",
    "        td_g_list[-1].find_all(\"a\")[0].text== \"3\"\n",
    "        url_v_pdf = td_g_list[-1].find(\"a\")[\"href\"]\n",
    "   \n",
    "            \n",
    "    \n",
    "    minidict_g={\"VorlageNR\":gesch_nr, \"Einreichedatum\":einger_am, \"Link Vorstoss-PDF\":url_v_pdf,}\n",
    "    for key, value in minidict_g.items():\n",
    "        if value == '':\n",
    "            minidict_g[key] = 'NaN'  #hier schaue ich noch, dass ich die Leeren Zeilen mit NAN ersetzten kann.\n",
    "        else:\n",
    "            minidict_g[key] = value\n",
    "            \n",
    "    eingang_list.append(minidict_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g=pd.DataFrame(eingang_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Das Datum muss noch als solches lesbar gemacht werden\n",
    "df_g[\"Einreichedatum\"] =  pd.to_datetime(df_g[\"Einreichedatum\"], format='%d.%m.%Y') #verwandle string in datum\n",
    "df_g[\"VorlageNR\"] =df_g[\"VorlageNR\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g.to_csv(\"KRFrames/df_g_LinkszuPDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g=pd.read_csv(\"KRFrames/df_g_LinkszuPDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PDFs der Vorstösse runterladen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in tqdm(df_g[\"Link Vorstoss-PDF\"]):\n",
    "    r = requests.get(\"https://kr-geschaefte.zug.ch\"+link, stream =True) #Das Stream braucht es, um mit dem Zip umgehen zu koennen\n",
    "    name = link.split(\"/\")[-1] #Der Computer kann mit \"/\" in einem Namen nicht umgehen, deshalb nehme ich die hier raus, und nehme nur den letzten Teil des NAmens.\n",
    "    with open(\"KRGeschPDF/\"+name, \"wb\") as f:\n",
    "        f.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. PDFs sind auf dem Rechner, nun lesbar machen und !Regex Baby!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nun will ich aus jedem PDF zum Einen die VorlagenNR rausziehen sowie Namen und Datum hier die Definition\n",
    "# ! Danke dem |$ am Schluss gibt es keinen Index-Error, wenn er kein Resultat findet.\n",
    "regex_vorlage= r\"VORLAGE.NR\\..(\\d*)\\.1|$\" #hier ziehe ich die Vorlagennummer raus. \n",
    "regex_datum = r\"VOM.(\\d+\\..\\w*.\\d{4})|$\" # hier gehe ich an das DAtum\n",
    "regex_name=r\"\\bVON(.*UND.*)\" #Hier muss ich noch überlegen, wie anders. Problem: zum Teil sind Namen einzeln zum teil mehr\n",
    "# Und irgendwie erkennt er die Zeilenende nicht.\n",
    "regex_name1= r\"\\bVON.(\\w*.\\w*\\b)\"\n",
    "regex_partei= r\"DER.(\\w*)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lösung online gefunden um aus dem PDF-Ordner eine Liste mit den Links herzustellen.\n",
    "pdf_files_list= [f for f in listdir(\"KRGeschPDF\") if isfile(join(\"KRGeschPDF\", f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pdf_files_list) #Ich habe ja die PDFs ignoriert, zu welchen ich auf Grund der Referenz keine PDF-Links hatte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!! ACHTUNG: zuerst mit einzelen testen. Möglicherweise findet er die Files nicht. \n",
    "dat_pdf_list=[]\n",
    "for dok in pdf_files_list:\n",
    "    mypdf = open(\"KRGeschPDF/\"+dok, mode='rb')\n",
    "    pdf_name = dok\n",
    "    pdf_document = PyPDF2.PdfFileReader(mypdf)\n",
    "    first_page = pdf_document.getPage(0)\n",
    "    front=first_page.extractText()\n",
    "    dat_p_ein= re.findall(regex_datum, front, re.IGNORECASE)[0] #Ich greiffe auf das Datum zu\n",
    "        # um zu verhindern, dass ich mehrer Daten und Vorlagen habe, sage ich mit [0] er soll das erste nehmen\n",
    "    vorl_p_nr= re.findall(regex_vorlage, front, re.IGNORECASE)[0] # Ich greiffe auf die Vorlagennummer zu (zum Zusammenfügen der Dataframes)\n",
    "    \n",
    "    minidict_pdf_dat={\"Einreichedatum\": dat_p_ein, \"VorlageNR\":vorl_p_nr, \"Filename\":pdf_name}\n",
    "    \n",
    "    dat_pdf_list.append(minidict_pdf_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p=pd.DataFrame(dat_pdf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p.sort_values(\"Einreichedatum\") #Stichproben haben gezeigt, dass die fehlerhaften Datumsangaben in GEschäftern sind,\n",
    "# Welche selber meist schon ein Datum haben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p.to_csv(\"KRFrames/INFOSausPDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Zeit in Datetime umwandeln\n",
    "schwierigkeit: wie bringe ich das deutsche Zeitformat in englisches. Mache ich es falsch oder gibts wieder probleme mit den Grossbuchstaben der Zeitformate? Hatten wir windowsuser auch schon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p=pd.read_csv(\"KRFrames/INFOSausPDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locale.setlocale(locale.LC_ALL, 'de_DE') # hier die Sprachwahl\n",
    "df_p[\"Einreichedatum\"] = pd.to_datetime(df_p[\"Einreichedatum\"], format= \"%d. %B %Y\", errors='coerce') #Angabe des Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df_p #Halleluia:-) habs doch noch geschafft. Und die wenigen, die falsch formiert sind, werden nicht auffallen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p.to_csv(\"KRFrames/KonvertierteDatenformate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p=pd.read_csv(\"KRFrames/KonvertierteDatenformate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nun noch ohne.0 hinten bei der VorlageNR. Ah es ist ein Float. Kann es also zu int oder str machen\n",
    "df_p[\"VorlageNR\"]=df_p[\"VorlageNR\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting(elem):\n",
    "    elem = elem.split('.')[0].strip()\n",
    "    return elem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p[\"VorlageNR\"]=df_p[\"VorlageNR\"].apply(splitting) # So, nun sind die .0 weg. Mal schauen. Das String-Format reicht wohl\n",
    "del df_p[\"Unnamed: 0\"] # die beiden Spalten entfernen\n",
    "del df_p[\"Unnamed: 0.1\"]\n",
    "df_ps=df_p.rename(columns={\"Filename\": \"Link Vorstoss-PDF\"}) #Spalte gleich benennen wie im anderen Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ps.to_csv(\"KRFrames/df_p_Datum\") # und speichern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Ein Dataframe machen, mit den PDF-Dokumentennamen\n",
    "- splitting funktion schreiben\n",
    "- auf Spalte anwenden\n",
    "- neu abspeichern "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splittpdf(elem):\n",
    "    elem = elem.split('/')[-1].strip()\n",
    "    return elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g[\"Link Vorstoss-PDF\"]=df_g[\"Link Vorstoss-PDF\"].apply(splittpdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g.to_csv(\"KRFrames/df_g_Datum_mit_PDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Nun zusammenfügen der beiden Daten-Dataframes anhand der PDF-Namen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g1=pd.read_csv(\"KRFrames/df_g_Datum_mit_PDF\")\n",
    "df_p1=pd.read_csv(\"KRFrames/df_p_Datum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dat_max=pd.merge(df_g1, df_p1, how=\"left\",on= \"Link Vorstoss-PDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dat_max.sort_values(\"Einreichedatum_x\").tail(100)  #So, jetzt sind zwar beide zusammen, aber noch nicht vereint\n",
    "#Jetzt noch irgendwie die beiden Einreichedaten miteinander ableichen/ergängen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 die Datenspalten zusammenbekommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hier füge ich sie zusammen\n",
    "df_dat_zus=df_dat_max.Einreichedatum_x.combine_first(df_dat_max.Einreichedatum_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dat_max['Einreichedatum'] = df_dat_zus # hier füge ich die neu enstandene \"Series\" dem Dataframe an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datum=df_dat_max[[\"Unnamed: 0_x\",\"VorlageNR_x\", \"Einreichedatum\", \"Link Vorstoss-PDF\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datum.to_csv(\"KRFrames/df_datum_ALLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Alle Dataframes zusammenfügen \n",
    "- Alle einlesen und auf die Unterseiten verweisen\n",
    "- eines nach dem andern anhängen\n",
    "- noch schön machen und kontrollieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen:\n",
    "df_v=pd.read_csv(\"KRFrames/df_v_Hauptseiten\") #Alle Vorstösse mit Infos mit Titel und Nummer der Page mit allen Geschäften\n",
    "df_dat_all=pd.read_csv(\"KRFrames/df_datum_ALLE\")# Frame mit allen Zeitangaben(Datum)(oben)\n",
    "df_np=pd.read_csv(\"KRFrames/Alle_Namen_mit_Allianz_und_ohne\")# Aus File \"02 Namen aus Geschäftsnamen...\" Alle Namen und Parteien\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VorlageNR</th>\n",
       "      <th>Geschäft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3020</td>\n",
       "      <td>Postulat von Luzian Franzini und Esther Haas b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3019</td>\n",
       "      <td>Motion von Luzian Franzini, Rita Hofer, Tabea ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3018</td>\n",
       "      <td>Interpellation von Fabio Iten, Laura Dittli un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3017</td>\n",
       "      <td>Postulat von Tabea Zimmermann Gibson, Stéphani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3014</td>\n",
       "      <td>Interpellation der SVP-Fraktion betreffend mob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1215</td>\n",
       "      <td>762</td>\n",
       "      <td>Motion der erweiterten Justizprüfungskommissio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1216</td>\n",
       "      <td>666</td>\n",
       "      <td>Motion der Kommission Teilrevision Personalges...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1217</td>\n",
       "      <td>304</td>\n",
       "      <td>Motion von Manuela Weichelt betreffend HIV-Prä...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1218</td>\n",
       "      <td>282</td>\n",
       "      <td>Motion von Christoph Hohler betreffend Radstre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1219</td>\n",
       "      <td>81</td>\n",
       "      <td>Motion der vorberatenden Kommission betreffend...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1220 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      VorlageNR                                           Geschäft\n",
       "0          3020  Postulat von Luzian Franzini und Esther Haas b...\n",
       "1          3019  Motion von Luzian Franzini, Rita Hofer, Tabea ...\n",
       "2          3018  Interpellation von Fabio Iten, Laura Dittli un...\n",
       "3          3017  Postulat von Tabea Zimmermann Gibson, Stéphani...\n",
       "4          3014  Interpellation der SVP-Fraktion betreffend mob...\n",
       "...         ...                                                ...\n",
       "1215        762  Motion der erweiterten Justizprüfungskommissio...\n",
       "1216        666  Motion der Kommission Teilrevision Personalges...\n",
       "1217        304  Motion von Manuela Weichelt betreffend HIV-Prä...\n",
       "1218        282  Motion von Christoph Hohler betreffend Radstre...\n",
       "1219         81  Motion der vorberatenden Kommission betreffend...\n",
       "\n",
       "[1220 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  zuerst vorputzen\n",
    "df_v1 = df_v[[\"VorlageNR\", \"Geschäft\"]].copy()\n",
    "df_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dat_all=df_dat_all.rename(columns={\"VorlageNR_x\": \"VorlageNR\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>VorlageNR</th>\n",
       "      <th>Einreichedatum</th>\n",
       "      <th>Link Vorstoss-PDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3020</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>3020-1-16168_Racial-Profiling.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3019</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>3019-1-16167_Chancengleichheit.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3018</td>\n",
       "      <td>2019-10-07</td>\n",
       "      <td>3018-1-16166_Praktikum.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3017</td>\n",
       "      <td>2019-10-06</td>\n",
       "      <td>3017-1-16165_Frauenwahl-stimmrecht_Feier.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3014</td>\n",
       "      <td>2019-09-26</td>\n",
       "      <td>3014-1-16159_Geschwindigkeitskontrollen-2-0.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1215</td>\n",
       "      <td>1215</td>\n",
       "      <td>1215</td>\n",
       "      <td>762</td>\n",
       "      <td>2005-10-31</td>\n",
       "      <td>pdoc_1047_1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1216</td>\n",
       "      <td>1216</td>\n",
       "      <td>1216</td>\n",
       "      <td>666</td>\n",
       "      <td>2002-06-06</td>\n",
       "      <td>pdoc_55_1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1217</td>\n",
       "      <td>1217</td>\n",
       "      <td>1217</td>\n",
       "      <td>304</td>\n",
       "      <td>2003-05-27</td>\n",
       "      <td>pdoc_50_1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>2635</td>\n",
       "      <td>1995-08-07</td>\n",
       "      <td>1620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1219</td>\n",
       "      <td>1219</td>\n",
       "      <td>1219</td>\n",
       "      <td>81</td>\n",
       "      <td>2007-04-10</td>\n",
       "      <td>pdoc_1705_1.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1220 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0_x  VorlageNR Einreichedatum  \\\n",
       "0              0             0       3020     2019-10-11   \n",
       "1              1             1       3019     2019-10-11   \n",
       "2              2             2       3018     2019-10-07   \n",
       "3              3             3       3017     2019-10-06   \n",
       "4              4             4       3014     2019-09-26   \n",
       "...          ...           ...        ...            ...   \n",
       "1215        1215          1215        762     2005-10-31   \n",
       "1216        1216          1216        666     2002-06-06   \n",
       "1217        1217          1217        304     2003-05-27   \n",
       "1218        1218          1218       2635     1995-08-07   \n",
       "1219        1219          1219         81     2007-04-10   \n",
       "\n",
       "                                    Link Vorstoss-PDF  \n",
       "0                   3020-1-16168_Racial-Profiling.pdf  \n",
       "1                  3019-1-16167_Chancengleichheit.pdf  \n",
       "2                          3018-1-16166_Praktikum.pdf  \n",
       "3        3017-1-16165_Frauenwahl-stimmrecht_Feier.pdf  \n",
       "4     3014-1-16159_Geschwindigkeitskontrollen-2-0.pdf  \n",
       "...                                               ...  \n",
       "1215                                  pdoc_1047_1.pdf  \n",
       "1216                                    pdoc_55_1.pdf  \n",
       "1217                                    pdoc_50_1.pdf  \n",
       "1218                                             1620  \n",
       "1219                                  pdoc_1705_1.pdf  \n",
       "\n",
       "[1220 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dat_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Nun zusammenfügen\n",
    "df_alles=pd.merge(df_v1, df_dat_all, how=\"inner\",on= \"VorlageNR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VorlageNR</th>\n",
       "      <th>Geschäft</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>Einreichedatum</th>\n",
       "      <th>Link Vorstoss-PDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3020</td>\n",
       "      <td>Postulat von Luzian Franzini und Esther Haas b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>3020-1-16168_Racial-Profiling.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3019</td>\n",
       "      <td>Motion von Luzian Franzini, Rita Hofer, Tabea ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>3019-1-16167_Chancengleichheit.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3018</td>\n",
       "      <td>Interpellation von Fabio Iten, Laura Dittli un...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-07</td>\n",
       "      <td>3018-1-16166_Praktikum.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3017</td>\n",
       "      <td>Postulat von Tabea Zimmermann Gibson, Stéphani...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-06</td>\n",
       "      <td>3017-1-16165_Frauenwahl-stimmrecht_Feier.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3014</td>\n",
       "      <td>Interpellation der SVP-Fraktion betreffend mob...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-09-26</td>\n",
       "      <td>3014-1-16159_Geschwindigkeitskontrollen-2-0.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>801</td>\n",
       "      <td>Motion von Hans Abicht betreffend Raumkonzept ...</td>\n",
       "      <td>1214</td>\n",
       "      <td>1214</td>\n",
       "      <td>2006-08-22</td>\n",
       "      <td>pdoc_1440_1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1141</td>\n",
       "      <td>762</td>\n",
       "      <td>Motion der erweiterten Justizprüfungskommissio...</td>\n",
       "      <td>1215</td>\n",
       "      <td>1215</td>\n",
       "      <td>2005-10-31</td>\n",
       "      <td>pdoc_1047_1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1142</td>\n",
       "      <td>666</td>\n",
       "      <td>Motion der Kommission Teilrevision Personalges...</td>\n",
       "      <td>1216</td>\n",
       "      <td>1216</td>\n",
       "      <td>2002-06-06</td>\n",
       "      <td>pdoc_55_1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1143</td>\n",
       "      <td>304</td>\n",
       "      <td>Motion von Manuela Weichelt betreffend HIV-Prä...</td>\n",
       "      <td>1217</td>\n",
       "      <td>1217</td>\n",
       "      <td>2003-05-27</td>\n",
       "      <td>pdoc_50_1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1144</td>\n",
       "      <td>81</td>\n",
       "      <td>Motion der vorberatenden Kommission betreffend...</td>\n",
       "      <td>1219</td>\n",
       "      <td>1219</td>\n",
       "      <td>2007-04-10</td>\n",
       "      <td>pdoc_1705_1.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1145 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      VorlageNR                                           Geschäft  \\\n",
       "0          3020  Postulat von Luzian Franzini und Esther Haas b...   \n",
       "1          3019  Motion von Luzian Franzini, Rita Hofer, Tabea ...   \n",
       "2          3018  Interpellation von Fabio Iten, Laura Dittli un...   \n",
       "3          3017  Postulat von Tabea Zimmermann Gibson, Stéphani...   \n",
       "4          3014  Interpellation der SVP-Fraktion betreffend mob...   \n",
       "...         ...                                                ...   \n",
       "1140        801  Motion von Hans Abicht betreffend Raumkonzept ...   \n",
       "1141        762  Motion der erweiterten Justizprüfungskommissio...   \n",
       "1142        666  Motion der Kommission Teilrevision Personalges...   \n",
       "1143        304  Motion von Manuela Weichelt betreffend HIV-Prä...   \n",
       "1144         81  Motion der vorberatenden Kommission betreffend...   \n",
       "\n",
       "      Unnamed: 0  Unnamed: 0_x Einreichedatum  \\\n",
       "0              0             0     2019-10-11   \n",
       "1              1             1     2019-10-11   \n",
       "2              2             2     2019-10-07   \n",
       "3              3             3     2019-10-06   \n",
       "4              4             4     2019-09-26   \n",
       "...          ...           ...            ...   \n",
       "1140        1214          1214     2006-08-22   \n",
       "1141        1215          1215     2005-10-31   \n",
       "1142        1216          1216     2002-06-06   \n",
       "1143        1217          1217     2003-05-27   \n",
       "1144        1219          1219     2007-04-10   \n",
       "\n",
       "                                    Link Vorstoss-PDF  \n",
       "0                   3020-1-16168_Racial-Profiling.pdf  \n",
       "1                  3019-1-16167_Chancengleichheit.pdf  \n",
       "2                          3018-1-16166_Praktikum.pdf  \n",
       "3        3017-1-16165_Frauenwahl-stimmrecht_Feier.pdf  \n",
       "4     3014-1-16159_Geschwindigkeitskontrollen-2-0.pdf  \n",
       "...                                               ...  \n",
       "1140                                  pdoc_1440_1.pdf  \n",
       "1141                                  pdoc_1047_1.pdf  \n",
       "1142                                    pdoc_55_1.pdf  \n",
       "1143                                    pdoc_50_1.pdf  \n",
       "1144                                  pdoc_1705_1.pdf  \n",
       "\n",
       "[1145 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_alles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Namenganz</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Judith Wild</td>\n",
       "      <td>FDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Madeleine Landolt</td>\n",
       "      <td>SGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Peter Bossard</td>\n",
       "      <td>FDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Susi Frei</td>\n",
       "      <td>FDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Alois Henggeler</td>\n",
       "      <td>CVP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>386</td>\n",
       "      <td>312</td>\n",
       "      <td>Iris  Hess-Brauer</td>\n",
       "      <td>CVP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>387</td>\n",
       "      <td>334</td>\n",
       "      <td>Mariann  Hess-Witschi</td>\n",
       "      <td>Kt.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>388</td>\n",
       "      <td>343</td>\n",
       "      <td>Magda  Feldmann-Müller</td>\n",
       "      <td>CSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>389</td>\n",
       "      <td>345</td>\n",
       "      <td>Sepp  Grob-Bieri</td>\n",
       "      <td>CVP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>367</td>\n",
       "      <td>Manuela  Käch-Schmid</td>\n",
       "      <td>CVP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>391 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0               Namenganz    P\n",
       "0             0             Judith Wild  FDP\n",
       "1             1       Madeleine Landolt  SGA\n",
       "2             2           Peter Bossard  FDP\n",
       "3             3              Susi Frei   FDP\n",
       "4             4         Alois Henggeler  CVP\n",
       "..          ...                     ...  ...\n",
       "386         312       Iris  Hess-Brauer  CVP\n",
       "387         334   Mariann  Hess-Witschi  Kt.\n",
       "388         343  Magda  Feldmann-Müller  CSP\n",
       "389         345        Sepp  Grob-Bieri  CVP\n",
       "390         367    Manuela  Käch-Schmid  CVP\n",
       "\n",
       "[391 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'VorlageNR'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-06da77d88c1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_alles_ganz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_alles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_np\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"inner\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"VorlageNR\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_tuti\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_alles_ganz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"VorlageNR\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Geschäft\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Namenganz\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"P\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Einreichedatum\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Stand\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Zuständigkeit\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Art des Geschäfts\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Status\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Link Vorstoss-PDF\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mindicator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     )\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 626\u001b[1;33m         ) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_rkey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 975\u001b[1;33m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    976\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m                             \u001b[1;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1772\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1773\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1774\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1776\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'VorlageNR'"
     ]
    }
   ],
   "source": [
    "df_alles_ganz=pd.merge(df_alles, df_np, how=\"inner\", on=\"VorlageNR\")\n",
    "df_tuti=df_alles_ganz[[\"VorlageNR\",\"Geschäft\", \"Namenganz\", \"P\", \"Einreichedatum\", \"Stand\", \"Zuständigkeit\", \"Art des Geschäfts\",\"Status\", \"Link Vorstoss-PDF\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tuti #Wieso wird es nicht ergänzt. Der Fehler ist im File 02 Namen passiert. dort nachschauen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XX Zum Resultat hier mal das Dataframe der Hauptseite sowie der Unterseiten zusammenfügen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mit_dat=pd.merge(df_a, df_g, how=\"left\", on=\"GeschäftsNR\") #ich verbinde die beiden DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nun will ich noch das Datum zum Idex machen\n",
    "df_mit_dat.set_index(\"Einreichedatum\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mit_dat.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ein erstes Ergebnis = ab 2013 alle  Vorstösse\n",
    "# ACHTUNG das stimmt ja so gar nicht, da bei mehreren Personen\n",
    "# auch mehrere Einreichungen verzeichnet werden!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nun will ich ein erstes Mal in die DAten schauen, zumindest ab 2013 - ob es ein Muster beim Einreichen gibt.\n",
    "#DAzu krame ich jetzt alle Vorstösse raus\n",
    "\n",
    "df_vo_all=df_mit_dat[{\"Art des Geschäfts\" : [\"Motion\",\"Interpellation\",\"Postulat\",\"Kleine Anfrage\"] }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mit_dat[\"Art des Geschäfts\"][\"GeschäftsNR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vo_all[\"2013\":].resample(\"SMS\").count().plot(figsize=(8,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regex Baby! \n",
    "### Ich versuche mit Regex in Pandas an die Namen zu kommen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nun versuche ich mit Regex an die einzelnen Namen zu kommen.\n",
    "regex_n=r\"\\bvon(.*und.\\w*.\\w*\\b)\"\n",
    "regex_n2= r\"^(\\w*.\\w*\\b)\\,.(\\w*.\\w*\\b)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n1=df_a['Geschäft'].str.extract(regex_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
