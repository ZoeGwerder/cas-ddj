{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Falsche Files finden und code anpassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import requests, zipfile, io #zum abspeichern von PDFs\n",
    "from tqdm import tqdm\n",
    "import PyPDF2\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Die einzelnen Geschäfte aufrufen und Infos rausholen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nun muss ich den Code ändern, sodass ich nicht mehr online zugreiffe sondern über meinen Ordner.\n",
    "#hier nun die Liste der Zugriffe.\n",
    "geschaefts_liste=[]#####ACHTUNG ich mache den RANGE kleiner, um weniger GEschäfte zu erhalten.\n",
    "\n",
    "for seite_g in range(0,1220): #Range für alle Geschäfte wäre 1219!\n",
    "    gesch= \"KRhtml/Geschaeft\"+str(seite_g)+\".html\"\n",
    "    geschaefts_liste.append(gesch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1220"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(geschaefts_liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KRhtml/Geschaeft1210.html',\n",
       " 'KRhtml/Geschaeft1211.html',\n",
       " 'KRhtml/Geschaeft1212.html',\n",
       " 'KRhtml/Geschaeft1213.html',\n",
       " 'KRhtml/Geschaeft1214.html',\n",
       " 'KRhtml/Geschaeft1215.html',\n",
       " 'KRhtml/Geschaeft1216.html',\n",
       " 'KRhtml/Geschaeft1217.html',\n",
       " 'KRhtml/Geschaeft1218.html',\n",
       " 'KRhtml/Geschaeft1219.html']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geschaefts_liste[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nun den Zugang zu den PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ich muss noch rausfinden, bei welchen Geschäften, wie ausgelesen werden muss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ich will hier mal schauen, wieviele  Geschäfte mit -1 funktionieren und wiviele nicht.\n",
    "truelist = []\n",
    "falselist = []\n",
    "for geschaeft in geschaefts_liste:\n",
    "    file = open(geschaeft, 'r')\n",
    "    text = file.read()\n",
    "    soup_g = BeautifulSoup(text, 'html.parser')\n",
    "    tr_g_list=soup_g.find_all(\"tr\")\n",
    "    td_g_list=tr_g_list[-1].find_all(\"td\")\n",
    "    if td_g_list[1].find_all(\"a\")[0].text== \"1\":\n",
    "        truelist.append(geschaeft)\n",
    "    else:\n",
    "        falselist.append(geschaeft)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1061"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(truelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'falselist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f6b01bef40b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfalselist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'falselist' is not defined"
     ]
    }
   ],
   "source": [
    "len(falselist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# und nun jene von den falschen, die mit -2 funktionieren\n",
    "# MANN geht nicht. Am Ende hat es eine leere Klammer, die bringe ich auch nicht weg, wenn ich das letzte Geschäft entferne\n",
    "# Es muss eines in der Mitte sein. Wie kann ich den Fehelr umgehen\n",
    "# Bin mit der Listenposition die GEschäfte duerchgegangen. ab 127 ist Problem.\n",
    "truelist_f = []\n",
    "falselist_f = []\n",
    "for geschaeft_f in falselist[:126]:\n",
    "    file = open(geschaeft_f, 'r')\n",
    "    text = file.read()\n",
    "    soup_g = BeautifulSoup(text, 'html.parser')\n",
    "    tr_f_list=soup_g.find_all(\"tr\")\n",
    "    td_f_list=tr_f_list[-2].find_all(\"td\")\n",
    "   \n",
    "    if  td_f_list[1].find_all(\"a\")[0].text == \"1\":\n",
    "        truelist_f.append(geschaeft_f)\n",
    "    else:\n",
    "        falselist_f.append(geschaeft_f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die problematischen GEschäfte haben keinen Vorstoss 1 mehr drin. \n",
    "# Diese muss ich mir einzeln runterziehen, da sie auch anders ausgelesen werden müssen.  \n",
    "ohne_vor_list_2=[]\n",
    "falselist_vor=[]\n",
    "for geschaeft_f in falselist[127:]:\n",
    "    file = open(geschaeft_f, 'r')\n",
    "    text = file.read()\n",
    "    soup_g = BeautifulSoup(text, 'html.parser')\n",
    "    tr_f_list=soup_g.find_all(\"tr\")\n",
    "    td_f_list=tr_f_list[-1].find_all(\"td\")\n",
    "   \n",
    "    if  td_f_list[1].find_all(\"a\")[0].text == \"2\":\n",
    "        ohne_vor_list_2.append(geschaeft_f)\n",
    "    else:\n",
    "        falselist_vor.append(geschaeft_f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KRhtml/Geschaeft1184.html',\n",
       " 'KRhtml/Geschaeft1186.html',\n",
       " 'KRhtml/Geschaeft1187.html',\n",
       " 'KRhtml/Geschaeft1188.html',\n",
       " 'KRhtml/Geschaeft1189.html',\n",
       " 'KRhtml/Geschaeft1190.html',\n",
       " 'KRhtml/Geschaeft1191.html',\n",
       " 'KRhtml/Geschaeft1193.html',\n",
       " 'KRhtml/Geschaeft1194.html',\n",
       " 'KRhtml/Geschaeft1195.html',\n",
       " 'KRhtml/Geschaeft1196.html',\n",
       " 'KRhtml/Geschaeft1197.html',\n",
       " 'KRhtml/Geschaeft1198.html',\n",
       " 'KRhtml/Geschaeft1199.html',\n",
       " 'KRhtml/Geschaeft1202.html',\n",
       " 'KRhtml/Geschaeft1203.html',\n",
       " 'KRhtml/Geschaeft1204.html',\n",
       " 'KRhtml/Geschaeft1205.html',\n",
       " 'KRhtml/Geschaeft1206.html',\n",
       " 'KRhtml/Geschaeft1207.html',\n",
       " 'KRhtml/Geschaeft1208.html',\n",
       " 'KRhtml/Geschaeft1209.html',\n",
       " 'KRhtml/Geschaeft1210.html',\n",
       " 'KRhtml/Geschaeft1211.html',\n",
       " 'KRhtml/Geschaeft1212.html',\n",
       " 'KRhtml/Geschaeft1213.html',\n",
       " 'KRhtml/Geschaeft1214.html',\n",
       " 'KRhtml/Geschaeft1217.html']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohne_vor_list_2 #Alle Vorstösse, bei welchen der zweite Teil rausgezogen werden müssen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KRhtml/Geschaeft1215.html',\n",
       " 'KRhtml/Geschaeft1216.html',\n",
       " 'KRhtml/Geschaeft1218.html',\n",
       " 'KRhtml/Geschaeft1219.html']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falselist_vor # Hier alle Vorstösse, die mit == \"3\" ausgelesen werden müssen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nun die Erkenntniss, dass nur die auszulesende Zahl nicht stimmt einfügen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hier  habe ich mich entschieden, auf den Zugriff der Namen zu verzichten, und dies einheitlich über die PDFs zu lösen.\n",
    "#Nun seite für Seite abrufen und in einem neuen Minidict unterbringen\n",
    "#ACHTUNG überprüfen: es bringt zumindest für einige die falschen Daten raus. und dann gleich mehrfach. \n",
    "#(Geschäft: 2129 8fach. Nur das richtige Datum ist nicht drinn.)\n",
    "eingang_list=[]\n",
    "\n",
    "\n",
    "for geschaeft in geschaefts_liste:\n",
    "    file = open(geschaeft, 'r')\n",
    "    text = file.read()\n",
    "    soup_g = BeautifulSoup(text, 'html.parser')\n",
    "    tr_g_list=soup_g.find_all(\"tr\")\n",
    "    td_g_list=tr_g_list[-1].find_all(\"td\")#hier gehe ich zum Dokument.\n",
    "    gesch_nr = tr_g_list[-1].find_all(\"td\")[0].text\n",
    "    einger_am = tr_g_list[1].find_all(\"td\")[0].text   \n",
    "    ul_list = tr_g_list[2].find_all(\"ul\")\n",
    "    li_list = ul_list[0].find_all(\"li\")\n",
    "   \n",
    "     #Da es zum Teil Referenzen hat, muss ich varieren.\n",
    "    \n",
    "    if td_g_list[-1].find_all(\"a\")[0].text== \"1\": #Ich brauche immer das Dokument 1. \n",
    "        url_v_pdf = td_g_list[-1].find(\"a\")[\"href\"]\n",
    "    elif td_g_list[-1].find_all(\"a\")[0].text== \"2\":\n",
    "        url_v_pdf = td_g_list[-1].find(\"a\")[\"href\"]   \n",
    "    else:  \n",
    "        td_g_list[-1].find_all(\"a\")[0].text== \"3\"\n",
    "        url_v_pdf = td_g_list[-1].find(\"a\")[\"href\"]\n",
    "    \n",
    "   \n",
    "\n",
    "    #ACHTUNG: dieses if-Konstrukt funktioniert nicht - doch if/else? Es kommt immer dasselbe resultat raus.        \n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "    minidict_g={\"VorlageNR\":gesch_nr, \"Einreichedatum\":einger_am, \"Link Vorstoss-PDF\":url_v_pdf}\n",
    "    for key, value in minidict_g.items():\n",
    "        if value == '':\n",
    "            minidict_g[key] = 'NaN'  #hier schaue ich noch, dass ich die Leeren Zeilen mit NAN ersetzten kann.\n",
    "        else:\n",
    "            minidict_g[key] = value\n",
    "            \n",
    "    eingang_list.append(minidict_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g=pd.DataFrame(eingang_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VorlageNR</th>\n",
       "      <th>Einreichedatum</th>\n",
       "      <th>Link Vorstoss-PDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3020</td>\n",
       "      <td>11.10.2019</td>\n",
       "      <td>/dokumente/8316/3020-1-16168_Racial-Profiling.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3019</td>\n",
       "      <td>11.10.2019</td>\n",
       "      <td>/dokumente/8317/3019-1-16167_Chancengleichheit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3018</td>\n",
       "      <td>07.10.2019</td>\n",
       "      <td>/dokumente/8310/3018-1-16166_Praktikum.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3017</td>\n",
       "      <td>06.10.2019</td>\n",
       "      <td>/dokumente/8311/3017-1-16165_Frauenwahl-stimmr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3014</td>\n",
       "      <td>26.09.2019</td>\n",
       "      <td>/dokumente/8312/3014-1-16159_Geschwindigkeitsk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1215</td>\n",
       "      <td>762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/dokumente/4232/pdoc_1047_1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1216</td>\n",
       "      <td>666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/dokumente/4215/pdoc_55_1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1217</td>\n",
       "      <td>304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/dokumente/4179/pdoc_50_1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1218</td>\n",
       "      <td>2635</td>\n",
       "      <td>07.08.1995</td>\n",
       "      <td>/gast/geschaefte/1620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1219</td>\n",
       "      <td>81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/dokumente/4236/pdoc_1705_1.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1220 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     VorlageNR Einreichedatum  \\\n",
       "0         3020     11.10.2019   \n",
       "1         3019     11.10.2019   \n",
       "2         3018     07.10.2019   \n",
       "3         3017     06.10.2019   \n",
       "4         3014     26.09.2019   \n",
       "...        ...            ...   \n",
       "1215       762            NaN   \n",
       "1216       666            NaN   \n",
       "1217       304            NaN   \n",
       "1218      2635     07.08.1995   \n",
       "1219        81            NaN   \n",
       "\n",
       "                                      Link Vorstoss-PDF  \n",
       "0     /dokumente/8316/3020-1-16168_Racial-Profiling.pdf  \n",
       "1     /dokumente/8317/3019-1-16167_Chancengleichheit...  \n",
       "2            /dokumente/8310/3018-1-16166_Praktikum.pdf  \n",
       "3     /dokumente/8311/3017-1-16165_Frauenwahl-stimmr...  \n",
       "4     /dokumente/8312/3014-1-16159_Geschwindigkeitsk...  \n",
       "...                                                 ...  \n",
       "1215                    /dokumente/4232/pdoc_1047_1.pdf  \n",
       "1216                      /dokumente/4215/pdoc_55_1.pdf  \n",
       "1217                      /dokumente/4179/pdoc_50_1.pdf  \n",
       "1218                              /gast/geschaefte/1620  \n",
       "1219                    /dokumente/4236/pdoc_1705_1.pdf  \n",
       "\n",
       "[1220 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g[\"Link Vorstoss-PDF\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDFs der Vorstösse runterladen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in tqdm(df_g[\"Link Vorstoss-PDF\"]):\n",
    "    r = requests.get(\"https://kr-geschaefte.zug.ch\"+link, stream =True) #Das Stream braucht es, um mit dem Zip umgehen zu koennen\n",
    "    name = link.split(\"/\")[-1] #Der Computer kann mit \"/\" in einem Namen nicht umgehen, deshalb nehme ich die hier raus, und nehme nur den letzten Teil des NAmens.\n",
    "    with open(\"KRGeschPDF/\"+name, \"wb\") as f:\n",
    "        f.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDFs sind auf dem Rechner, nun lesbar machen und !Regex Baby!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nun will ich aus jedem PDF zum Einen die VorlagenNR rausziehen sowie Namen und Datum hier die Definition\n",
    "# ! Danke dem |$ am Schluss gibt es keinen Index-Error, wenn er kein Resultat findet.\n",
    "regex_vorlage= r\"VORLAGE.NR\\..(\\d*)\\.1|$\" #hier ziehe ich die Vorlagennummer raus. \n",
    "regex_datum = r\"VOM.(\\d+\\..\\w*.\\d{4})|$\" # hier gehe ich an das DAtum\n",
    "regex_name=r\"\\bVON(.*UND.*)\" #Hier muss ich noch überlegen, wie anders. Problem: zum Teil sind Namen einzeln zum teil mehr\n",
    "# Und irgendwie erkennt er die Zeilenende nicht.\n",
    "regex_name1= r\"\\bVON.(\\w*.\\w*\\b)\"\n",
    "regex_partei= r\"DER.(\\w*)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lösung online gefunden um aus dem PDF-Ordner eine Liste mit den Links herzustellen.\n",
    "pdf_files_list= [f for f in listdir(\"KRGeschPDF\") if isfile(join(\"KRGeschPDF\", f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!! ACHTUNG: zuerst mit einzelen testen. Möglicherweise findet er die Files nicht. \n",
    "dat_pdf_list=[]\n",
    "for dok in pdf_files_list:\n",
    "    mypdf = open(\"KRGeschPDF/\"+dok, mode='rb')\n",
    "    pdf_document = PyPDF2.PdfFileReader(mypdf)\n",
    "    first_page = pdf_document.getPage(0)\n",
    "    front=first_page.extractText()\n",
    "    dat_p_ein= re.findall(regex_datum, front, re.IGNORECASE)[0] #Ich greiffe auf das Datum zu\n",
    "        # um zu verhindern, dass ich mehrer Daten und Vorlagen habe, sage ich mit [0] er soll das erste nehmen\n",
    "    vorl_p_nr= re.findall(regex_vorlage, front, re.IGNORECASE)[0] # Ich greiffe auf die Vorlagennummer zu (zum Zusammenfügen der Dataframes)\n",
    "    \n",
    "    minidict_pdf_dat={\"Einreichedatum\": dat_p_ein, \"VorlageNR\":vorl_p_nr}\n",
    "    \n",
    "    dat_pdf_list.append(minidict_pdf_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p=pd.DataFrame(dat_pdf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Das Datenformat in englisch umwandeln und lesbar machen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hmmmmm jetzt chumi nümm wiiter. Muss die Monate ins Englische umwandeln.\n",
    "d={\"JANUAR\":\"January\", \"FEBRUAR\":\"February\", \"MÄRZ\":\"March\", \"APRIL\":\"April\", \"MAI\":\"May\",\"JUNI\":\"June\",\"JULI\":\"Juli\",\"AUGUST\":\"August\",\"SEPTEMBER\":\"September\",\"OKTOBER\":\"October\",\"NOVEMBER\":\"November\", \"DEZEMBER\":\"December\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zum Resultat hier mal das Dataframe der Hauptseite sowie der Unterseiten zusammenfügen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mit_dat=pd.merge(df_a, df_g, how=\"left\", on=\"GeschäftsNR\") #ich verbinde die beiden DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nun will ich noch das Datum zum Idex machen\n",
    "df_mit_dat.set_index(\"Einreichedatum\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mit_dat.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ein erstes Ergebnis = ab 2013 alle  Vorstösse\n",
    "# ACHTUNG das stimmt ja so gar nicht, da bei mehreren Personen\n",
    "# auch mehrere Einreichungen verzeichnet werden!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nun will ich ein erstes Mal in die DAten schauen, zumindest ab 2013 - ob es ein Muster beim Einreichen gibt.\n",
    "#DAzu krame ich jetzt alle Vorstösse raus\n",
    "\n",
    "df_vo_all=df_mit_dat[{\"Art des Geschäfts\" : [\"Motion\",\"Interpellation\",\"Postulat\",\"Kleine Anfrage\"] }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mit_dat[\"Art des Geschäfts\"][\"GeschäftsNR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vo_all[\"2013\":].resample(\"SMS\").count().plot(figsize=(8,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regex Baby! \n",
    "### Ich versuche mit Regex in Pandas an die Namen zu kommen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nun versuche ich mit Regex an die einzelnen Namen zu kommen.\n",
    "regex_n=r\"\\bvon(.*und.\\w*.\\w*\\b)\"\n",
    "regex_n2= r\"^(\\w*.\\w*\\b)\\,.(\\w*.\\w*\\b)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n1=df_a['Geschäft'].str.extract(regex_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
